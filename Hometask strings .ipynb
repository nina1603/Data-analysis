{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import linear_model \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nina\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from collections import Counter\n",
    "import logging\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('привет!! как дело?\\n', 'привет как дела')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('negative.csv', sep=';', header=None, encoding='utf-8',\\\n",
    "                  names=['id1','id2','nick','comment','index1','index2','index3','index4','index5','index6','index7','index8'])\n",
    "df2 = pd.read_csv('positive.csv', sep=';', encoding = 'utf-8', header=None, \\\n",
    "                 names=['id1','id2','nick','comment','index1','index2','index3','index4','index5','index6','index7','index8'])\n",
    "df1['index'] = 0\n",
    "df2['index'] = 1\n",
    "df = df1.append(df2)\n",
    "\n",
    "\n",
    "al = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '\n",
    "\n",
    "def no_pun(s):\n",
    "    return ''.join(x for x in s.lower() if x in al)\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "def lem(text):\n",
    "    lemmas = m.lemmatize(text)\n",
    "    return ''.join(lemmas)\n",
    "lem('Привет!! как дела?'), no_pun('Привет!! как дела?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114911,)\n",
      "(111923,)\n"
     ]
    }
   ],
   "source": [
    "#pos = df2[3]\n",
    "#print(pos.shape)\n",
    "#neg = df1[3]\n",
    "#print(neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "df['clear_comment'] = df.comment.apply(\\\n",
    "                            lambda text: morph.parse(re.sub('[^а-яА-Я ]', '', ''.join(str(text)).lower()))[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitting():\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "        if '' in self.sentences:\n",
    "            self.sentences.remove('')\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (s.split() for s in self.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(sentences):\n",
    "    if '' in sentences:\n",
    "        sentences.remove('')\n",
    "    return (s.split() for s in sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = Splitting(list(df.clear_comment))\n",
    "model = Word2Vec(words, min_count=30, hs = 0, workers = 4, sg=0, iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример работы ворд2века: модель обучена нормально\n",
    "words = model.wv.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectors = pd.DataFrame(model.wv.vectors)\n",
    "vectors['words'] = words\n",
    "vectorizer = TfidfVectorizer(min_df = 30)\n",
    "texts_tfidf = vectorizer.fit_transform(df.clear_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fn = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = texts_tfidf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = pd.DataFrame(fn, columns = ['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6203, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.merge(word, vectors, on = 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6278, 101)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6203, 101)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = f.iloc[:,1:].values.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = np.matrix(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.3912025 ,  0.4128594 ,  0.80275023, ..., -0.21250527,\n",
       "         -0.63431686,  0.5096467 ],\n",
       "        [ 0.98595387,  0.39626396, -0.31937283, ..., -0.32830134,\n",
       "         -0.8976158 , -0.09088632],\n",
       "        [ 1.1960278 ,  0.37108126, -0.95495933, ..., -0.41504523,\n",
       "         -0.25617343,  1.4324073 ],\n",
       "        ...,\n",
       "        [ 1.0194621 ,  1.0912251 ,  0.3914889 , ...,  0.4198572 ,\n",
       "         -1.281239  ,  1.3694355 ],\n",
       "        [ 2.143502  ,  0.762172  ,  1.7059977 , ..., -0.05147666,\n",
       "          0.08823078, -0.9549198 ],\n",
       "        [-1.5098135 , -0.19606103, -0.153078  , ...,  1.2810558 ,\n",
       "         -0.5516037 , -0.90586656]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226834, 6203)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = vecs*(mt.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fm.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clusters = KMeans(n_clusters = 10).fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(word, morth = pymorphy2.MorphAnalyzer()):\n",
    "    return morth.parse(word)[0].tag.POS\n",
    "\n",
    "functors_pos = {'INTJ', 'PRCL', 'CONJ', 'PREP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster = 6\n",
      "rows amount: 20222\n",
      "key words + frequency\n",
      "('я', 3981) ('день', 2600) ('уже', 2156) ('сегодня', 1808) ('меня', 1649) ('год', 1558) ('все', 1420) ('новый', 1339) ('будет', 1306) ('завтра', 1289) ('года', 996) ('нас', 856) ('мы', 848) ('раз', 725) ('скоро', 714) ('дня', 709) ('нг', 612) ('мне', 604) ('нет', 584) ('буду', 512) ('два', 451) ('первый', 447) ('теперь', 443) ('всего', 428) ('последний', 427) ('хочу', 425) ('недели', 417) ('очень', 408) ('настроение', 403) ('ещ', 396)\n",
      "\n",
      "cluster = 9\n",
      "rows amount: 20398\n",
      "key words + frequency\n",
      "('я', 3566) ('все', 2653) ('они', 2179) ('меня', 2054) ('мы', 1785) ('вы', 1628) ('такие', 1335) ('люди', 1158) ('мне', 1142) ('нас', 1135) ('их', 994) ('мои', 883) ('вас', 744) ('уже', 708) ('кто', 704) ('были', 677) ('там', 662) ('которые', 655) ('нет', 635) ('всех', 602) ('почему', 588) ('эти', 577) ('людей', 574) ('них', 519) ('очень', 500) ('будут', 462) ('тоже', 441) ('какие', 435) ('ты', 427) ('люблю', 418)\n",
      "\n",
      "cluster = 3\n",
      "rows amount: 11514\n",
      "key words + frequency\n",
      "('я', 2585) ('всем', 1202) ('тебе', 1124) ('очень', 977) ('тебя', 830) ('люблю', 711) ('рождения', 710) ('вам', 672) ('мне', 646) ('днем', 633) ('меня', 552) ('скучаю', 549) ('день', 545) ('привет', 517) ('утро', 515) ('сегодня', 500) ('доброе', 471) ('все', 462) ('вас', 406) ('ты', 380) ('скучать', 340) ('буду', 294) ('желаю', 285) ('удачи', 285) ('вечер', 267) ('уже', 265) ('поздравляю', 264) ('будет', 263) ('настроение', 261) ('дня', 256)\n",
      "\n",
      "cluster = 0\n",
      "rows amount: 38858\n",
      "key words + frequency\n",
      "('я', 6548) ('меня', 2011) ('все', 1323) ('сегодня', 1184) ('мне', 1089) ('уже', 1057) ('теперь', 932) ('мы', 897) ('там', 719) ('тут', 592) ('ты', 547) ('сейчас', 527) ('опять', 510) ('нас', 508) ('вчера', 490) ('оо', 439) ('сижу', 383) ('потом', 372) ('тоже', 370) ('где', 344) ('пока', 337) ('весь', 335) ('будет', 329) ('вромайдан', 327) ('видео', 325) ('нам', 323) ('нет', 319) ('раз', 318) ('смотрю', 303) ('л', 296)\n",
      "\n",
      "cluster = 2\n",
      "rows amount: 31890\n",
      "key words + frequency\n",
      "('я', 9299) ('все', 3886) ('меня', 3678) ('мне', 3138) ('очень', 2401) ('было', 2273) ('нет', 1774) ('уже', 1664) ('вс', 1649) ('вообще', 1360) ('тоже', 1272) ('быть', 1247) ('ничего', 999) ('будет', 999) ('хорошо', 958) ('тебя', 930) ('больше', 913) ('время', 910) ('ты', 880) ('сейчас', 857) ('много', 852) ('плохо', 822) ('сегодня', 815) ('там', 777) ('всегда', 740) ('почему', 699) ('такое', 689) ('теперь', 661) ('мы', 650) ('чтото', 645)\n",
      "\n",
      "cluster = 1\n",
      "rows amount: 25757\n",
      "key words + frequency\n",
      "('я', 10571) ('ты', 8015) ('мне', 3637) ('меня', 2894) ('тебя', 2641) ('тебе', 2286) ('все', 1954) ('он', 1848) ('знаю', 1217) ('кто', 1154) ('почему', 1076) ('его', 935) ('она', 916) ('тоже', 893) ('уже', 838) ('нет', 824) ('быть', 789) ('там', 768) ('вообще', 687) ('люблю', 636) ('никто', 634) ('будет', 633) ('может', 628) ('вс', 607) ('тут', 595) ('тогда', 592) ('всегда', 556) ('ничего', 550) ('никогда', 537) ('очень', 533)\n",
      "\n",
      "cluster = 4\n",
      "rows amount: 24235\n",
      "key words + frequency\n",
      "('я', 8438) ('мне', 3049) ('хочу', 2671) ('надо', 2602) ('могу', 1852) ('меня', 1610) ('все', 1446) ('можно', 1320) ('уже', 1273) ('буду', 977) ('нужно', 924) ('нет', 844) ('делать', 782) ('теперь', 738) ('его', 702) ('будет', 689) ('себе', 677) ('было', 673) ('знаю', 664) ('тоже', 659) ('может', 614) ('ты', 612) ('ничего', 610) ('хочется', 591) ('хотела', 584) ('сделать', 573) ('там', 565) ('сейчас', 531) ('лучше', 504) ('вообще', 501)\n",
      "\n",
      "cluster = 8\n",
      "rows amount: 18932\n",
      "key words + frequency\n",
      "('я', 4419) ('он', 2729) ('меня', 2135) ('мой', 1971) ('мне', 1461) ('его', 1378) ('был', 1358) ('ты', 1271) ('такой', 1110) ('этот', 1091) ('один', 798) ('самый', 760) ('какой', 662) ('кто', 635) ('который', 633) ('очень', 629) ('все', 627) ('человек', 623) ('сегодня', 614) ('уже', 614) ('тебя', 594) ('тот', 590) ('день', 553) ('раз', 487) ('фильм', 394) ('момент', 393) ('новый', 393) ('твой', 374) ('любимый', 373) ('него', 368)\n",
      "\n",
      "cluster = 5\n",
      "rows amount: 15565\n",
      "key words + frequency\n",
      "('я', 3540) ('меня', 2212) ('она', 1653) ('моя', 1535) ('такая', 1238) ('ты', 1070) ('мне', 1067) ('была', 1012) ('эта', 688) ('все', 592) ('какая', 573) ('тебя', 557) ('одна', 504) ('жизнь', 488) ('ее', 485) ('сегодня', 454) ('очень', 450) ('уже', 441) ('нас', 424) ('мама', 409) ('самая', 386) ('тоже', 339) ('теперь', 325) ('та', 321) ('вся', 321) ('будет', 316) ('там', 283) ('любовь', 264) ('сейчас', 246) ('нет', 244)\n",
      "\n",
      "cluster = 7\n",
      "rows amount: 19463\n",
      "key words + frequency\n",
      "('я', 6538) ('завтра', 2391) ('спать', 2068) ('сегодня', 1771) ('мне', 1679) ('уже', 1621) ('меня', 1616) ('хочу', 1612) ('все', 1300) ('надо', 1152) ('дома', 1071) ('домой', 973) ('день', 866) ('школу', 846) ('болит', 812) ('идти', 771) ('опять', 735) ('буду', 734) ('утра', 690) ('часа', 669) ('делать', 668) ('теперь', 646) ('сейчас', 632) ('пойду', 564) ('утро', 549) ('потом', 513) ('ночь', 492) ('вообще', 490) ('очень', 488) ('могу', 477)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clust in df['cluster'].unique():\n",
    "    lst = [item for sublist in df[df['cluster'] ==clust]['clear_comment'].apply(lambda x: x.split()) for item in sublist]\n",
    "    cnt = Counter(lst)\n",
    "    print('cluster = '+ str(clust))\n",
    "    print('rows amount: '+ str(df[df['cluster'] == clust].shape[0]))\n",
    "    print('key words + frequency')\n",
    "    print(*[word for word in cnt.most_common(100) if pos(word[0]) not in functors_pos][:30])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
