{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import linear_model \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nina\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from collections import Counter\n",
    "import logging\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('привет!! как дело?\\n', 'привет как дела')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('negative.csv', sep=';', header=None, encoding='utf-8',\\\n",
    "                  names=['id1','id2','nick','comment','index1','index2','index3','index4','index5','index6','index7','index8'])\n",
    "df2 = pd.read_csv('positive.csv', sep=';', encoding = 'utf-8', header=None, \\\n",
    "                 names=['id1','id2','nick','comment','index1','index2','index3','index4','index5','index6','index7','index8'])\n",
    "df1['index'] = 0\n",
    "df2['index'] = 1\n",
    "df = df1.append(df2)\n",
    "\n",
    "\n",
    "al = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '\n",
    "\n",
    "def no_pun(s):\n",
    "    return ''.join(x for x in s.lower() if x in al)\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "def lem(text):\n",
    "    lemmas = m.lemmatize(text)\n",
    "    return ''.join(lemmas)\n",
    "lem('Привет!! как дела?'), no_pun('Привет!! как дела?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114911,)\n",
      "(111923,)\n"
     ]
    }
   ],
   "source": [
    "#pos = df2[3]\n",
    "#print(pos.shape)\n",
    "#neg = df1[3]\n",
    "#print(neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "df['del_comment'] = df.comment.apply(\\\n",
    "                            lambda text: morph.parse(re.sub('[^а-яА-Я ]', '', ''.join(str(text)).lower()))[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(sentences):\n",
    "    if '' in sentences:\n",
    "        sentences.remove('')\n",
    "    return (s.split() for s in sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = splitting(list(df.clear_comment))\n",
    "model = Word2Vec(words, min_count=30, hs = 0, workers = 4, sg=0, iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectors = pd.DataFrame(model.wv.vectors)\n",
    "vectors['words'] = words\n",
    "vectorizer = TfidfVectorizer(min_df = 30)\n",
    "texts_tfidf = vectorizer.fit_transform(df.clear_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fn = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = texts_tfidf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = pd.DataFrame(fn, columns = ['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6203, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.merge(word, vectors, on = 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6278, 101)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6203, 101)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = f.iloc[:,1:].values.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = np.matrix(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.3912025 ,  0.4128594 ,  0.80275023, ..., -0.21250527,\n",
       "         -0.63431686,  0.5096467 ],\n",
       "        [ 0.98595387,  0.39626396, -0.31937283, ..., -0.32830134,\n",
       "         -0.8976158 , -0.09088632],\n",
       "        [ 1.1960278 ,  0.37108126, -0.95495933, ..., -0.41504523,\n",
       "         -0.25617343,  1.4324073 ],\n",
       "        ...,\n",
       "        [ 1.0194621 ,  1.0912251 ,  0.3914889 , ...,  0.4198572 ,\n",
       "         -1.281239  ,  1.3694355 ],\n",
       "        [ 2.143502  ,  0.762172  ,  1.7059977 , ..., -0.05147666,\n",
       "          0.08823078, -0.9549198 ],\n",
       "        [-1.5098135 , -0.19606103, -0.153078  , ...,  1.2810558 ,\n",
       "         -0.5516037 , -0.90586656]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226834, 6203)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = vecs*(mt.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fm.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clusters = KMeans(n_clusters = 15).fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(word, morth = pymorphy2.MorphAnalyzer()):\n",
    "    return morth.parse(word)[0].tag.POS\n",
    "\n",
    "functors_pos = {'INTJ', 'PRCL', 'CONJ', 'PREP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster = 12\n",
      "rows amount: 14066\n",
      "key words + frequency\n",
      "('я', 3043) ('день', 2081) ('уже', 1891) ('год', 1685) ('новый', 1427) ('меня', 1132) ('года', 1090) ('все', 925) ('сегодня', 923) ('будет', 777) ('раз', 713) ('дня', 649) ('нг', 526) ('нет', 524) ('мне', 476) ('скоро', 458) ('мы', 450) ('два', 437) ('дней', 404) ('нас', 401) ('всего', 383) ('месяц', 379) ('этот', 375) ('недели', 370) ('последний', 349) ('нового', 349) ('первый', 349) ('буду', 342) ('теперь', 331) ('хочу', 330)\n",
      "\n",
      "cluster = 9\n",
      "rows amount: 14228\n",
      "key words + frequency\n",
      "('я', 2602) ('все', 2194) ('они', 1980) ('мы', 1513) ('вы', 1343) ('такие', 1316) ('меня', 1261) ('люди', 1068) ('мне', 911) ('мои', 875) ('их', 713) ('были', 640) ('нас', 640) ('эти', 558) ('которые', 526) ('уже', 507) ('вас', 495) ('там', 435) ('почему', 423) ('будут', 403) ('какие', 401) ('люблю', 379) ('очень', 379) ('самые', 337) ('те', 333) ('ты', 333) ('тоже', 318) ('всегда', 318) ('кто', 313) ('наши', 292)\n",
      "\n",
      "cluster = 14\n",
      "rows amount: 9680\n",
      "key words + frequency\n",
      "('я', 1900) ('всем', 1166) ('тебе', 1020) ('тебя', 727) ('рождения', 705) ('вам', 636) ('днем', 627) ('очень', 623) ('люблю', 576) ('день', 539) ('привет', 476) ('скучаю', 461) ('утро', 450) ('меня', 444) ('сегодня', 431) ('доброе', 424) ('все', 382) ('мне', 370) ('вас', 363) ('скучать', 300) ('ты', 300) ('желаю', 285) ('удачи', 275) ('поздравляю', 259) ('дня', 258) ('хорошего', 256) ('буду', 250) ('будет', 245) ('днм', 236) ('вечер', 231)\n",
      "\n",
      "cluster = 2\n",
      "rows amount: 20360\n",
      "key words + frequency\n",
      "('я', 3893) ('меня', 2909) ('нет', 1708) ('все', 1051) ('мне', 930) ('кто', 747) ('уже', 679) ('всех', 651) ('там', 632) ('больше', 617) ('нас', 557) ('теперь', 493) ('много', 462) ('нуть', 420) ('людей', 419) ('будет', 415) ('он', 407) ('фото', 402) ('где', 399) ('вообще', 395) ('тут', 388) ('их', 381) ('ты', 379) ('тоже', 379) ('кого', 376) ('его', 375) ('изза', 368) ('один', 364) ('почему', 360) ('тебя', 344)\n",
      "\n",
      "cluster = 6\n",
      "rows amount: 29119\n",
      "key words + frequency\n",
      "('я', 4661) ('сегодня', 1454) ('меня', 1392) ('мы', 1116) ('все', 1046) ('уже', 881) ('мне', 806) ('теперь', 714) ('нас', 692) ('вчера', 473) ('там', 458) ('сейчас', 449) ('опять', 405) ('тут', 358) ('сижу', 355) ('снег', 352) ('весь', 347) ('нам', 331) ('будет', 330) ('потом', 326) ('вромайдан', 316) ('пока', 302) ('день', 299) ('хочу', 295) ('раз', 283) ('тоже', 282) ('очень', 281) ('дома', 265) ('было', 263) ('снова', 251)\n",
      "\n",
      "cluster = 10\n",
      "rows amount: 21887\n",
      "key words + frequency\n",
      "('я', 5770) ('все', 2971) ('очень', 2369) ('мне', 2256) ('меня', 2047) ('было', 2019) ('вс', 1320) ('уже', 964) ('хорошо', 943) ('тоже', 835) ('время', 794) ('вообще', 765) ('плохо', 736) ('сегодня', 725) ('будет', 725) ('быть', 699) ('настроение', 689) ('тебя', 650) ('такое', 630) ('всегда', 613) ('ты', 610) ('сейчас', 589) ('мы', 575) ('нет', 532) ('както', 471) ('круто', 450) ('нас', 438) ('там', 436) ('много', 428) ('чтото', 423)\n",
      "\n",
      "cluster = 0\n",
      "rows amount: 22216\n",
      "key words + frequency\n",
      "('я', 9517) ('ты', 5733) ('мне', 3458) ('меня', 2506) ('тебя', 2210) ('все', 2075) ('тебе', 1751) ('он', 1715) ('знаю', 1305) ('быть', 1108) ('почему', 1067) ('кто', 1039) ('нет', 968) ('его', 931) ('уже', 847) ('она', 840) ('ничего', 805) ('тоже', 775) ('никогда', 747) ('может', 739) ('вообще', 734) ('больше', 723) ('будет', 712) ('очень', 692) ('вс', 688) ('люблю', 673) ('никто', 655) ('там', 577) ('всегда', 570) ('могу', 533)\n",
      "\n",
      "cluster = 3\n",
      "rows amount: 22426\n",
      "key words + frequency\n",
      "('я', 7140) ('ты', 3237) ('меня', 2102) ('мне', 1734) ('все', 1067) ('тебя', 828) ('тебе', 771) ('уже', 735) ('там', 731) ('тут', 641) ('тоже', 637) ('теперь', 614) ('он', 495) ('вообще', 462) ('ахах', 443) ('че', 426) ('ахаха', 398) ('она', 365) ('давай', 357) ('где', 349) ('оо', 343) ('зачем', 333) ('ахахах', 327) ('сейчас', 319) ('ладно', 315) ('потом', 306) ('буду', 305) ('его', 301) ('вы', 298) ('тогда', 297)\n",
      "\n",
      "cluster = 5\n",
      "rows amount: 19873\n",
      "key words + frequency\n",
      "('я', 7224) ('хочу', 2832) ('мне', 2579) ('надо', 2457) ('могу', 1719) ('все', 1307) ('меня', 1289) ('уже', 1162) ('можно', 1122) ('нужно', 846) ('буду', 826) ('хочется', 741) ('делать', 723) ('было', 694) ('нет', 684) ('ничего', 678) ('тоже', 579) ('его', 577) ('хотела', 570) ('будет', 566) ('теперь', 554) ('себе', 550) ('знаю', 529) ('сделать', 523) ('вообще', 519) ('сейчас', 492) ('быть', 488) ('ты', 482) ('лучше', 463) ('может', 456)\n",
      "\n",
      "cluster = 4\n",
      "rows amount: 15016\n",
      "key words + frequency\n",
      "('я', 3509) ('он', 2371) ('мой', 1886) ('меня', 1548) ('был', 1266) ('мне', 1193) ('его', 1164) ('ты', 1125) ('такой', 997) ('этот', 962) ('самый', 764) ('какой', 595) ('который', 570) ('один', 565) ('тот', 557) ('очень', 556) ('сегодня', 543) ('человек', 518) ('тебя', 509) ('все', 498) ('день', 493) ('уже', 478) ('кто', 452) ('раз', 396) ('фильм', 393) ('любимый', 377) ('момент', 367) ('твой', 365) ('хороший', 335) ('новый', 334)\n",
      "\n",
      "cluster = 7\n",
      "rows amount: 10850\n",
      "key words + frequency\n",
      "('я', 2933) ('завтра', 2855) ('сегодня', 1006) ('меня', 892) ('все', 820) ('мне', 786) ('уже', 687) ('будет', 678) ('буду', 580) ('надо', 537) ('день', 465) ('школу', 457) ('хочу', 435) ('делать', 428) ('мы', 406) ('скоро', 364) ('нас', 342) ('экзамен', 338) ('уроки', 337) ('потом', 304) ('пойду', 299) ('урок', 279) ('опять', 273) ('понедельник', 262) ('теперь', 255) ('учить', 254) ('школа', 254) ('идти', 248) ('ещ', 247) ('сейчас', 246)\n",
      "\n",
      "cluster = 11\n",
      "rows amount: 12193\n",
      "key words + frequency\n",
      "('я', 2626) ('меня', 1653) ('моя', 1510) ('она', 1417) ('такая', 1129) ('была', 936) ('мне', 820) ('ты', 785) ('эта', 626) ('какая', 502) ('все', 469) ('тебя', 451) ('жизнь', 442) ('одна', 430) ('очень', 413) ('ее', 403) ('самая', 394) ('сегодня', 385) ('уже', 353) ('нас', 348) ('мама', 317) ('вся', 293) ('будет', 276) ('тоже', 270) ('любовь', 267) ('теперь', 240) ('любимая', 239) ('песня', 231) ('хорошая', 230) ('которая', 221)\n",
      "\n",
      "cluster = 13\n",
      "rows amount: 13504\n",
      "key words + frequency\n",
      "('я', 4511) ('спать', 1921) ('меня', 1236) ('сегодня', 1229) ('уже', 1228) ('хочу', 1038) ('мне', 1036) ('дома', 873) ('болит', 866) ('все', 858) ('день', 786) ('домой', 784) ('завтра', 702) ('утра', 696) ('утро', 688) ('надо', 655) ('часа', 633) ('опять', 536) ('теперь', 482) ('ночь', 476) ('ночи', 465) ('голова', 461) ('идти', 446) ('сейчас', 442) ('вставать', 423) ('часов', 419) ('могу', 411) ('школу', 394) ('очень', 369) ('буду', 365)\n",
      "\n",
      "cluster = 8\n",
      "rows amount: 1260\n",
      "key words + frequency\n",
      "('нь', 284) ('л', 245) ('юм', 213) ('гэж', 141) ('байна', 129) ('иван', 122) ('царевич', 122) ('серый', 122) ('волк', 122) ('ч', 121) ('энэ', 104) ('би', 90) ('чинь', 89) ('дээр', 89) ('хн', 88) ('дээ', 88) ('ш', 82) ('д', 82) ('нэг', 79) ('дождались', 74) ('официальный', 74) ('трейлер', 74) ('смотреть', 74) ('всем', 74) ('толи', 74) ('быть', 74) ('бол', 73) ('демотиватор', 72) ('шинэ', 71) ('гэсэн', 71)\n",
      "\n",
      "cluster = 1\n",
      "rows amount: 156\n",
      "key words + frequency\n",
      "('офигенный', 156) ('деньдень', 156) ('позитивабегал', 156) ('идиот', 156) ('целый', 156) ('деньтанцы', 156) ('офигенны', 156) ('я', 156) ('ракал', 156) ('мне', 156) ('очень', 156) ('понравиться', 156)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clust in df['cluster'].unique():\n",
    "    lst = [item for sublist in df[df['cluster'] ==clust]['del_comment'].apply(lambda x: x.split()) for item in sublist]\n",
    "    cnt = Counter(lst)\n",
    "    print('cluster = '+ str(clust))\n",
    "    print('rows amount: '+ str(df[df['cluster'] == clust].shape[0]))\n",
    "    print('key words + frequency')\n",
    "    print(*[word for word in cnt.most_common(100) if pos(word[0]) not in functors_pos][:30])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
