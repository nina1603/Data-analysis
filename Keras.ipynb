{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as ks\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston, load_breast_cancer, load_iris\n",
    "# boston - regression\n",
    "# breast - binary\n",
    "# iris - multiclass\n",
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 13)\n",
      "(106, 13)\n",
      "(106,)\n"
     ]
    }
   ],
   "source": [
    "train = X[:400]\n",
    "y_train = y[:400]\n",
    "print(train.shape)\n",
    "test = X[400:]\n",
    "y_test = y[400:]\n",
    "print(test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычисляем среднее значение и стандартное отклонение, нормализуем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднее значение\n",
    "mean = train.mean(axis=0)\n",
    "# Стандартное отклонение\n",
    "std = train.std(axis=0)\n",
    "train -= mean\n",
    "train /= std\n",
    "test -= mean\n",
    "test /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation = 'relu', input_shape = (train.shape[1],)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь выходной слой с одним линейным нейроном - для задачи регрессии функция активации не используется. Функция ошибки - среднеквадратичное отклонение. Метрика - среднее абсолютное отклонение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 0s - loss: 1.3825 - mean_absolute_error: 0.8580\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.4399 - mean_absolute_error: 0.8607\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.4338 - mean_absolute_error: 0.8587\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.4627 - mean_absolute_error: 0.8901\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.3291 - mean_absolute_error: 0.8264\n",
      "Epoch 6/200\n",
      " - 0s - loss: 1.3580 - mean_absolute_error: 0.8382\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.3657 - mean_absolute_error: 0.8327\n",
      "Epoch 8/200\n",
      " - 0s - loss: 1.2604 - mean_absolute_error: 0.8066\n",
      "Epoch 9/200\n",
      " - 0s - loss: 1.3958 - mean_absolute_error: 0.8537\n",
      "Epoch 10/200\n",
      " - 0s - loss: 1.3088 - mean_absolute_error: 0.8230\n",
      "Epoch 11/200\n",
      " - 0s - loss: 1.4255 - mean_absolute_error: 0.8556\n",
      "Epoch 12/200\n",
      " - 0s - loss: 1.3719 - mean_absolute_error: 0.8430\n",
      "Epoch 13/200\n",
      " - 0s - loss: 1.3699 - mean_absolute_error: 0.8376\n",
      "Epoch 14/200\n",
      " - 0s - loss: 1.3382 - mean_absolute_error: 0.8435\n",
      "Epoch 15/200\n",
      " - 0s - loss: 1.3364 - mean_absolute_error: 0.8149\n",
      "Epoch 16/200\n",
      " - 0s - loss: 1.2432 - mean_absolute_error: 0.8101\n",
      "Epoch 17/200\n",
      " - 0s - loss: 1.2713 - mean_absolute_error: 0.8107\n",
      "Epoch 18/200\n",
      " - 0s - loss: 1.3182 - mean_absolute_error: 0.8316\n",
      "Epoch 19/200\n",
      " - 0s - loss: 1.3262 - mean_absolute_error: 0.8292\n",
      "Epoch 20/200\n",
      " - 0s - loss: 1.2863 - mean_absolute_error: 0.8100\n",
      "Epoch 21/200\n",
      " - 0s - loss: 1.2875 - mean_absolute_error: 0.8156\n",
      "Epoch 22/200\n",
      " - 0s - loss: 1.3540 - mean_absolute_error: 0.8494\n",
      "Epoch 23/200\n",
      " - 0s - loss: 1.2472 - mean_absolute_error: 0.8025\n",
      "Epoch 24/200\n",
      " - 0s - loss: 1.3212 - mean_absolute_error: 0.8341\n",
      "Epoch 25/200\n",
      " - 0s - loss: 1.2545 - mean_absolute_error: 0.8008\n",
      "Epoch 26/200\n",
      " - 0s - loss: 1.2748 - mean_absolute_error: 0.8149\n",
      "Epoch 27/200\n",
      " - 0s - loss: 1.3105 - mean_absolute_error: 0.8440\n",
      "Epoch 28/200\n",
      " - 0s - loss: 1.2310 - mean_absolute_error: 0.8051\n",
      "Epoch 29/200\n",
      " - 0s - loss: 1.2582 - mean_absolute_error: 0.8243\n",
      "Epoch 30/200\n",
      " - 0s - loss: 1.3320 - mean_absolute_error: 0.8401\n",
      "Epoch 31/200\n",
      " - 0s - loss: 1.3113 - mean_absolute_error: 0.8199\n",
      "Epoch 32/200\n",
      " - 0s - loss: 1.3413 - mean_absolute_error: 0.8453\n",
      "Epoch 33/200\n",
      " - 0s - loss: 1.3384 - mean_absolute_error: 0.8251\n",
      "Epoch 34/200\n",
      " - 0s - loss: 1.3393 - mean_absolute_error: 0.8299\n",
      "Epoch 35/200\n",
      " - 0s - loss: 1.4498 - mean_absolute_error: 0.9009\n",
      "Epoch 36/200\n",
      " - 0s - loss: 1.2572 - mean_absolute_error: 0.8146\n",
      "Epoch 37/200\n",
      " - 0s - loss: 1.2859 - mean_absolute_error: 0.8160\n",
      "Epoch 38/200\n",
      " - 0s - loss: 1.3174 - mean_absolute_error: 0.8328\n",
      "Epoch 39/200\n",
      " - 0s - loss: 1.2861 - mean_absolute_error: 0.8139\n",
      "Epoch 40/200\n",
      " - 0s - loss: 1.2634 - mean_absolute_error: 0.7989\n",
      "Epoch 41/200\n",
      " - 0s - loss: 1.1775 - mean_absolute_error: 0.7794\n",
      "Epoch 42/200\n",
      " - 0s - loss: 1.3043 - mean_absolute_error: 0.8222\n",
      "Epoch 43/200\n",
      " - 0s - loss: 1.2579 - mean_absolute_error: 0.8195\n",
      "Epoch 44/200\n",
      " - 0s - loss: 1.2296 - mean_absolute_error: 0.8058\n",
      "Epoch 45/200\n",
      " - 0s - loss: 1.2382 - mean_absolute_error: 0.8060\n",
      "Epoch 46/200\n",
      " - 0s - loss: 1.2599 - mean_absolute_error: 0.8105\n",
      "Epoch 47/200\n",
      " - 0s - loss: 1.2036 - mean_absolute_error: 0.7793\n",
      "Epoch 48/200\n",
      " - 0s - loss: 1.1841 - mean_absolute_error: 0.7728\n",
      "Epoch 49/200\n",
      " - 0s - loss: 1.2087 - mean_absolute_error: 0.7910\n",
      "Epoch 50/200\n",
      " - 0s - loss: 1.2028 - mean_absolute_error: 0.7869\n",
      "Epoch 51/200\n",
      " - 0s - loss: 1.2553 - mean_absolute_error: 0.7995\n",
      "Epoch 52/200\n",
      " - 0s - loss: 1.2331 - mean_absolute_error: 0.7994\n",
      "Epoch 53/200\n",
      " - 0s - loss: 1.2734 - mean_absolute_error: 0.8332\n",
      "Epoch 54/200\n",
      " - 0s - loss: 1.2001 - mean_absolute_error: 0.7802\n",
      "Epoch 55/200\n",
      " - 0s - loss: 1.2642 - mean_absolute_error: 0.8196\n",
      "Epoch 56/200\n",
      " - 0s - loss: 1.2050 - mean_absolute_error: 0.7853\n",
      "Epoch 57/200\n",
      " - 0s - loss: 1.2050 - mean_absolute_error: 0.7994\n",
      "Epoch 58/200\n",
      " - 0s - loss: 1.3304 - mean_absolute_error: 0.8528\n",
      "Epoch 59/200\n",
      " - 0s - loss: 1.2136 - mean_absolute_error: 0.8017\n",
      "Epoch 60/200\n",
      " - 0s - loss: 1.2867 - mean_absolute_error: 0.8124\n",
      "Epoch 61/200\n",
      " - 0s - loss: 1.2774 - mean_absolute_error: 0.8362\n",
      "Epoch 62/200\n",
      " - 0s - loss: 1.3250 - mean_absolute_error: 0.8467\n",
      "Epoch 63/200\n",
      " - 0s - loss: 1.2580 - mean_absolute_error: 0.8153\n",
      "Epoch 64/200\n",
      " - 0s - loss: 1.2900 - mean_absolute_error: 0.8208\n",
      "Epoch 65/200\n",
      " - 0s - loss: 1.1965 - mean_absolute_error: 0.7801\n",
      "Epoch 66/200\n",
      " - 0s - loss: 1.2520 - mean_absolute_error: 0.8213\n",
      "Epoch 67/200\n",
      " - 0s - loss: 1.2770 - mean_absolute_error: 0.8018\n",
      "Epoch 68/200\n",
      " - 0s - loss: 1.2390 - mean_absolute_error: 0.8008\n",
      "Epoch 69/200\n",
      " - 0s - loss: 1.2243 - mean_absolute_error: 0.8008\n",
      "Epoch 70/200\n",
      " - 0s - loss: 1.3095 - mean_absolute_error: 0.8328\n",
      "Epoch 71/200\n",
      " - 0s - loss: 1.2064 - mean_absolute_error: 0.8077\n",
      "Epoch 72/200\n",
      " - 0s - loss: 1.1856 - mean_absolute_error: 0.7729\n",
      "Epoch 73/200\n",
      " - 0s - loss: 1.1776 - mean_absolute_error: 0.7839\n",
      "Epoch 74/200\n",
      " - 0s - loss: 1.1960 - mean_absolute_error: 0.7973\n",
      "Epoch 75/200\n",
      " - 0s - loss: 1.1475 - mean_absolute_error: 0.7714\n",
      "Epoch 76/200\n",
      " - 0s - loss: 1.1911 - mean_absolute_error: 0.7832\n",
      "Epoch 77/200\n",
      " - 0s - loss: 1.1418 - mean_absolute_error: 0.7678\n",
      "Epoch 78/200\n",
      " - 0s - loss: 1.1718 - mean_absolute_error: 0.7772\n",
      "Epoch 79/200\n",
      " - 0s - loss: 1.1821 - mean_absolute_error: 0.7869\n",
      "Epoch 80/200\n",
      " - 0s - loss: 1.1522 - mean_absolute_error: 0.7721\n",
      "Epoch 81/200\n",
      " - 0s - loss: 1.2331 - mean_absolute_error: 0.8003\n",
      "Epoch 82/200\n",
      " - 0s - loss: 1.1264 - mean_absolute_error: 0.7592\n",
      "Epoch 83/200\n",
      " - 0s - loss: 1.1417 - mean_absolute_error: 0.7685\n",
      "Epoch 84/200\n",
      " - 0s - loss: 1.1315 - mean_absolute_error: 0.7630\n",
      "Epoch 85/200\n",
      " - 0s - loss: 1.1719 - mean_absolute_error: 0.7752\n",
      "Epoch 86/200\n",
      " - 0s - loss: 1.1310 - mean_absolute_error: 0.7584\n",
      "Epoch 87/200\n",
      " - 0s - loss: 1.1112 - mean_absolute_error: 0.7542\n",
      "Epoch 88/200\n",
      " - 0s - loss: 1.1286 - mean_absolute_error: 0.7548\n",
      "Epoch 89/200\n",
      " - 0s - loss: 1.1866 - mean_absolute_error: 0.7875\n",
      "Epoch 90/200\n",
      " - 0s - loss: 1.1091 - mean_absolute_error: 0.7553\n",
      "Epoch 91/200\n",
      " - 0s - loss: 1.1562 - mean_absolute_error: 0.7589\n",
      "Epoch 92/200\n",
      " - 0s - loss: 1.0822 - mean_absolute_error: 0.7521\n",
      "Epoch 93/200\n",
      " - 0s - loss: 1.2149 - mean_absolute_error: 0.8199\n",
      "Epoch 94/200\n",
      " - 0s - loss: 1.2487 - mean_absolute_error: 0.8041\n",
      "Epoch 95/200\n",
      " - 0s - loss: 1.1250 - mean_absolute_error: 0.7575\n",
      "Epoch 96/200\n",
      " - 0s - loss: 1.1062 - mean_absolute_error: 0.7614\n",
      "Epoch 97/200\n",
      " - 0s - loss: 1.1322 - mean_absolute_error: 0.7893\n",
      "Epoch 98/200\n",
      " - 0s - loss: 1.1587 - mean_absolute_error: 0.7856\n",
      "Epoch 99/200\n",
      " - 0s - loss: 1.1401 - mean_absolute_error: 0.7825\n",
      "Epoch 100/200\n",
      " - 0s - loss: 1.1253 - mean_absolute_error: 0.7641\n",
      "Epoch 101/200\n",
      " - 0s - loss: 1.1471 - mean_absolute_error: 0.7740\n",
      "Epoch 102/200\n",
      " - 0s - loss: 1.1470 - mean_absolute_error: 0.7696\n",
      "Epoch 103/200\n",
      " - 0s - loss: 1.0825 - mean_absolute_error: 0.7538\n",
      "Epoch 104/200\n",
      " - 0s - loss: 1.2031 - mean_absolute_error: 0.7916\n",
      "Epoch 105/200\n",
      " - 0s - loss: 1.1329 - mean_absolute_error: 0.7663\n",
      "Epoch 106/200\n",
      " - 0s - loss: 1.0889 - mean_absolute_error: 0.7580\n",
      "Epoch 107/200\n",
      " - 0s - loss: 1.0559 - mean_absolute_error: 0.7405\n",
      "Epoch 108/200\n",
      " - 0s - loss: 1.1395 - mean_absolute_error: 0.7636\n",
      "Epoch 109/200\n",
      " - 0s - loss: 1.1061 - mean_absolute_error: 0.7558\n",
      "Epoch 110/200\n",
      " - 0s - loss: 1.0600 - mean_absolute_error: 0.7343\n",
      "Epoch 111/200\n",
      " - 0s - loss: 1.1034 - mean_absolute_error: 0.7535\n",
      "Epoch 112/200\n",
      " - 0s - loss: 1.0748 - mean_absolute_error: 0.7458\n",
      "Epoch 113/200\n",
      " - 0s - loss: 1.1141 - mean_absolute_error: 0.7666\n",
      "Epoch 114/200\n",
      " - 0s - loss: 1.0410 - mean_absolute_error: 0.7298\n",
      "Epoch 115/200\n",
      " - 0s - loss: 1.0774 - mean_absolute_error: 0.7400\n",
      "Epoch 116/200\n",
      " - 0s - loss: 1.0574 - mean_absolute_error: 0.7484\n",
      "Epoch 117/200\n",
      " - 0s - loss: 1.1387 - mean_absolute_error: 0.7788\n",
      "Epoch 118/200\n",
      " - 0s - loss: 1.0962 - mean_absolute_error: 0.7624\n",
      "Epoch 119/200\n",
      " - 0s - loss: 1.0684 - mean_absolute_error: 0.7426\n",
      "Epoch 120/200\n",
      " - 0s - loss: 1.0729 - mean_absolute_error: 0.7440\n",
      "Epoch 121/200\n",
      " - 0s - loss: 1.0595 - mean_absolute_error: 0.7277\n",
      "Epoch 122/200\n",
      " - 0s - loss: 1.1085 - mean_absolute_error: 0.7705\n",
      "Epoch 123/200\n",
      " - 0s - loss: 1.0856 - mean_absolute_error: 0.7526\n",
      "Epoch 124/200\n",
      " - 0s - loss: 1.0506 - mean_absolute_error: 0.7326\n",
      "Epoch 125/200\n",
      " - 0s - loss: 1.1573 - mean_absolute_error: 0.7823\n",
      "Epoch 126/200\n",
      " - 0s - loss: 1.0940 - mean_absolute_error: 0.7533\n",
      "Epoch 127/200\n",
      " - 0s - loss: 1.2459 - mean_absolute_error: 0.8447\n",
      "Epoch 128/200\n",
      " - 0s - loss: 1.1293 - mean_absolute_error: 0.7470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200\n",
      " - 0s - loss: 1.0934 - mean_absolute_error: 0.7644\n",
      "Epoch 130/200\n",
      " - 0s - loss: 1.0639 - mean_absolute_error: 0.7449\n",
      "Epoch 131/200\n",
      " - 0s - loss: 1.0829 - mean_absolute_error: 0.7505\n",
      "Epoch 132/200\n",
      " - 0s - loss: 1.0290 - mean_absolute_error: 0.7299\n",
      "Epoch 133/200\n",
      " - 0s - loss: 1.0610 - mean_absolute_error: 0.7408\n",
      "Epoch 134/200\n",
      " - 0s - loss: 1.1585 - mean_absolute_error: 0.7976\n",
      "Epoch 135/200\n",
      " - 0s - loss: 1.0808 - mean_absolute_error: 0.7475\n",
      "Epoch 136/200\n",
      " - 0s - loss: 1.1561 - mean_absolute_error: 0.7854\n",
      "Epoch 137/200\n",
      " - 0s - loss: 1.0204 - mean_absolute_error: 0.7266\n",
      "Epoch 138/200\n",
      " - 0s - loss: 1.0423 - mean_absolute_error: 0.7333\n",
      "Epoch 139/200\n",
      " - 0s - loss: 1.0560 - mean_absolute_error: 0.7335\n",
      "Epoch 140/200\n",
      " - 0s - loss: 1.1474 - mean_absolute_error: 0.7532\n",
      "Epoch 141/200\n",
      " - 0s - loss: 1.1698 - mean_absolute_error: 0.7533\n",
      "Epoch 142/200\n",
      " - 0s - loss: 1.0672 - mean_absolute_error: 0.7325\n",
      "Epoch 143/200\n",
      " - 0s - loss: 1.1064 - mean_absolute_error: 0.7672\n",
      "Epoch 144/200\n",
      " - 0s - loss: 1.0680 - mean_absolute_error: 0.7425\n",
      "Epoch 145/200\n",
      " - 0s - loss: 1.0254 - mean_absolute_error: 0.7280\n",
      "Epoch 146/200\n",
      " - 0s - loss: 1.0309 - mean_absolute_error: 0.7299\n",
      "Epoch 147/200\n",
      " - 0s - loss: 1.0198 - mean_absolute_error: 0.7311\n",
      "Epoch 148/200\n",
      " - 0s - loss: 1.0152 - mean_absolute_error: 0.7173\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.9831 - mean_absolute_error: 0.7096\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.9982 - mean_absolute_error: 0.7063\n",
      "Epoch 151/200\n",
      " - 0s - loss: 1.0072 - mean_absolute_error: 0.7134\n",
      "Epoch 152/200\n",
      " - 0s - loss: 1.0196 - mean_absolute_error: 0.7170\n",
      "Epoch 153/200\n",
      " - 0s - loss: 1.1021 - mean_absolute_error: 0.7580\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.9726 - mean_absolute_error: 0.7008\n",
      "Epoch 155/200\n",
      " - 0s - loss: 1.0771 - mean_absolute_error: 0.7527\n",
      "Epoch 156/200\n",
      " - 0s - loss: 1.0109 - mean_absolute_error: 0.7084\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.9826 - mean_absolute_error: 0.7104\n",
      "Epoch 158/200\n",
      " - 0s - loss: 1.0735 - mean_absolute_error: 0.7457\n",
      "Epoch 159/200\n",
      " - 0s - loss: 1.1216 - mean_absolute_error: 0.7873\n",
      "Epoch 160/200\n",
      " - 0s - loss: 1.0908 - mean_absolute_error: 0.7640\n",
      "Epoch 161/200\n",
      " - 0s - loss: 1.0960 - mean_absolute_error: 0.7535\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.9944 - mean_absolute_error: 0.7268\n",
      "Epoch 163/200\n",
      " - 0s - loss: 1.0989 - mean_absolute_error: 0.7593\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.9978 - mean_absolute_error: 0.7210\n",
      "Epoch 165/200\n",
      " - 0s - loss: 1.0468 - mean_absolute_error: 0.7461\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.9998 - mean_absolute_error: 0.7257\n",
      "Epoch 167/200\n",
      " - 0s - loss: 1.1168 - mean_absolute_error: 0.7563\n",
      "Epoch 168/200\n",
      " - 0s - loss: 1.1135 - mean_absolute_error: 0.7521\n",
      "Epoch 169/200\n",
      " - 0s - loss: 1.0720 - mean_absolute_error: 0.7344\n",
      "Epoch 170/200\n",
      " - 0s - loss: 1.0430 - mean_absolute_error: 0.7411\n",
      "Epoch 171/200\n",
      " - 0s - loss: 1.0544 - mean_absolute_error: 0.7471\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.9622 - mean_absolute_error: 0.7071\n",
      "Epoch 173/200\n",
      " - 0s - loss: 1.0095 - mean_absolute_error: 0.7251\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.9799 - mean_absolute_error: 0.7001\n",
      "Epoch 175/200\n",
      " - 0s - loss: 1.0787 - mean_absolute_error: 0.7680\n",
      "Epoch 176/200\n",
      " - 0s - loss: 1.0186 - mean_absolute_error: 0.7161\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.9656 - mean_absolute_error: 0.6996\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.9850 - mean_absolute_error: 0.7077\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.9921 - mean_absolute_error: 0.6980\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.9848 - mean_absolute_error: 0.7184\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.9656 - mean_absolute_error: 0.7026\n",
      "Epoch 182/200\n",
      " - 0s - loss: 1.0123 - mean_absolute_error: 0.7262\n",
      "Epoch 183/200\n",
      " - 0s - loss: 1.0083 - mean_absolute_error: 0.7090\n",
      "Epoch 184/200\n",
      " - 0s - loss: 1.0206 - mean_absolute_error: 0.7158\n",
      "Epoch 185/200\n",
      " - 0s - loss: 1.0197 - mean_absolute_error: 0.7339\n",
      "Epoch 186/200\n",
      " - 0s - loss: 1.0357 - mean_absolute_error: 0.7325\n",
      "Epoch 187/200\n",
      " - 0s - loss: 1.0256 - mean_absolute_error: 0.7476\n",
      "Epoch 188/200\n",
      " - 0s - loss: 1.0018 - mean_absolute_error: 0.7260\n",
      "Epoch 189/200\n",
      " - 0s - loss: 1.0362 - mean_absolute_error: 0.7282\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.9699 - mean_absolute_error: 0.7178\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.9562 - mean_absolute_error: 0.7085\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.9464 - mean_absolute_error: 0.6991\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.9916 - mean_absolute_error: 0.7210\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.9745 - mean_absolute_error: 0.7045\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.9439 - mean_absolute_error: 0.7058\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.9406 - mean_absolute_error: 0.6854\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.9939 - mean_absolute_error: 0.7164\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.9757 - mean_absolute_error: 0.7202\n",
      "Epoch 199/200\n",
      " - 0s - loss: 1.0642 - mean_absolute_error: 0.7459\n",
      "Epoch 200/200\n",
      " - 0s - loss: 1.0278 - mean_absolute_error: 0.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2664d1f37b8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs = 200, batch_size = 9, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оцениваем точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, mae = model.evaluate(test, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя абсолютная ошибка: 6.920190217360011\n"
     ]
    }
   ],
   "source": [
    "print(\"Средняя абсолютная ошибка:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказано: 12.487502 , правильно 12.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Предсказано:\", pred[2][0], \", правильно\", y_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бинарная классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 30)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = X[:400]\n",
    "test = X[400:]\n",
    "y_train = y[:400]\n",
    "y_test = y[400:]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "# для бинарной классификации на выходе 1 нейрон и сигмоид\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# успешная сходимость регулируется оптимайзером, нужно обращать внимание на скорость сходимости lr\n",
    "adam = Adam(lr=0.00001)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "400/400 [==============================] - 0s 337us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 2/150\n",
      "400/400 [==============================] - 0s 490us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 3/150\n",
      "400/400 [==============================] - 0s 540us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 4/150\n",
      "400/400 [==============================] - 0s 466us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 5/150\n",
      "400/400 [==============================] - 0s 460us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 6/150\n",
      "400/400 [==============================] - 0s 504us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 7/150\n",
      "400/400 [==============================] - 0s 507us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 8/150\n",
      "400/400 [==============================] - 0s 515us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 9/150\n",
      "400/400 [==============================] - 0s 472us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 10/150\n",
      "400/400 [==============================] - 0s 540us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 11/150\n",
      "400/400 [==============================] - 0s 453us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 12/150\n",
      "400/400 [==============================] - 0s 515us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 13/150\n",
      "400/400 [==============================] - 0s 460us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 14/150\n",
      "400/400 [==============================] - 0s 528us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 15/150\n",
      "400/400 [==============================] - 0s 482us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 16/150\n",
      "400/400 [==============================] - 0s 495us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 17/150\n",
      "400/400 [==============================] - 0s 502us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 18/150\n",
      "400/400 [==============================] - 0s 532us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 19/150\n",
      "400/400 [==============================] - 0s 457us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 20/150\n",
      "400/400 [==============================] - 0s 482us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 21/150\n",
      "400/400 [==============================] - 0s 510us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 22/150\n",
      "400/400 [==============================] - 0s 485us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 23/150\n",
      "400/400 [==============================] - 0s 547us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 24/150\n",
      "400/400 [==============================] - 0s 542us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 25/150\n",
      "400/400 [==============================] - 0s 512us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 26/150\n",
      "400/400 [==============================] - 0s 457us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 27/150\n",
      "400/400 [==============================] - 0s 455us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 28/150\n",
      "400/400 [==============================] - 0s 477us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 29/150\n",
      "400/400 [==============================] - 0s 408us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 30/150\n",
      "400/400 [==============================] - 0s 442us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 31/150\n",
      "400/400 [==============================] - 0s 465us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 32/150\n",
      "400/400 [==============================] - 0s 395us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 33/150\n",
      "400/400 [==============================] - 0s 440us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 34/150\n",
      "400/400 [==============================] - 0s 430us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 35/150\n",
      "400/400 [==============================] - 0s 457us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 36/150\n",
      "400/400 [==============================] - 0s 387us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 37/150\n",
      "400/400 [==============================] - 0s 343us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 38/150\n",
      "400/400 [==============================] - 0s 457us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 39/150\n",
      "400/400 [==============================] - 0s 425us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 40/150\n",
      "400/400 [==============================] - 0s 403us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 41/150\n",
      "400/400 [==============================] - 0s 435us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 42/150\n",
      "400/400 [==============================] - 0s 432us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 43/150\n",
      "400/400 [==============================] - 0s 442us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 44/150\n",
      "400/400 [==============================] - 0s 435us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 45/150\n",
      "400/400 [==============================] - 0s 402us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 46/150\n",
      "400/400 [==============================] - 0s 387us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 47/150\n",
      "400/400 [==============================] - 0s 410us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 48/150\n",
      "400/400 [==============================] - 0s 337us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 49/150\n",
      "400/400 [==============================] - 0s 350us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 50/150\n",
      "400/400 [==============================] - 0s 417us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 51/150\n",
      "400/400 [==============================] - 0s 387us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 52/150\n",
      "400/400 [==============================] - 0s 347us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 53/150\n",
      "400/400 [==============================] - 0s 457us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 54/150\n",
      "400/400 [==============================] - 0s 345us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 55/150\n",
      "400/400 [==============================] - 0s 397us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 56/150\n",
      "400/400 [==============================] - 0s 392us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 57/150\n",
      "400/400 [==============================] - 0s 380us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 58/150\n",
      "400/400 [==============================] - 0s 357us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 59/150\n",
      "400/400 [==============================] - 0s 338us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 60/150\n",
      "400/400 [==============================] - 0s 337us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 61/150\n",
      "400/400 [==============================] - 0s 340us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 62/150\n",
      "400/400 [==============================] - 0s 345us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 63/150\n",
      "400/400 [==============================] - 0s 332us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 64/150\n",
      "400/400 [==============================] - 0s 355us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 65/150\n",
      "400/400 [==============================] - 0s 350us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 66/150\n",
      "400/400 [==============================] - 0s 317us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 67/150\n",
      "400/400 [==============================] - 0s 342us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 68/150\n",
      "400/400 [==============================] - 0s 362us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 69/150\n",
      "400/400 [==============================] - 0s 355us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 70/150\n",
      "400/400 [==============================] - 0s 377us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 71/150\n",
      "400/400 [==============================] - 0s 347us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 72/150\n",
      "400/400 [==============================] - 0s 392us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 73/150\n",
      "400/400 [==============================] - 0s 365us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 74/150\n",
      "400/400 [==============================] - 0s 372us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 75/150\n",
      "400/400 [==============================] - 0s 337us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 76/150\n",
      "400/400 [==============================] - 0s 387us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 77/150\n",
      "400/400 [==============================] - 0s 392us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 78/150\n",
      "400/400 [==============================] - 0s 370us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 79/150\n",
      "400/400 [==============================] - 0s 380us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 80/150\n",
      "400/400 [==============================] - 0s 563us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 81/150\n",
      "400/400 [==============================] - 0s 375us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 82/150\n",
      "400/400 [==============================] - 0s 368us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 370us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 84/150\n",
      "400/400 [==============================] - 0s 432us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 85/150\n",
      "400/400 [==============================] - 0s 435us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 86/150\n",
      "400/400 [==============================] - 0s 410us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 87/150\n",
      "400/400 [==============================] - 0s 352us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 88/150\n",
      "400/400 [==============================] - 0s 420us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 89/150\n",
      "400/400 [==============================] - 0s 387us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 90/150\n",
      "400/400 [==============================] - 0s 445us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 91/150\n",
      "400/400 [==============================] - 0s 437us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 92/150\n",
      "400/400 [==============================] - 0s 398us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 93/150\n",
      "400/400 [==============================] - 0s 447us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 94/150\n",
      "400/400 [==============================] - 0s 408us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 95/150\n",
      "400/400 [==============================] - 0s 367us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 96/150\n",
      "400/400 [==============================] - 0s 367us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 97/150\n",
      "400/400 [==============================] - 0s 427us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 98/150\n",
      "400/400 [==============================] - 0s 445us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 99/150\n",
      "400/400 [==============================] - 0s 455us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 100/150\n",
      "400/400 [==============================] - 0s 433us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 101/150\n",
      "400/400 [==============================] - 0s 442us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 102/150\n",
      "400/400 [==============================] - 0s 412us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 103/150\n",
      "400/400 [==============================] - 0s 387us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 104/150\n",
      "400/400 [==============================] - 0s 437us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 105/150\n",
      "400/400 [==============================] - 0s 522us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 106/150\n",
      "400/400 [==============================] - 0s 532us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 107/150\n",
      "400/400 [==============================] - 0s 398us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 108/150\n",
      "400/400 [==============================] - 0s 392us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 109/150\n",
      "400/400 [==============================] - 0s 405us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 110/150\n",
      "400/400 [==============================] - 0s 447us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 111/150\n",
      "400/400 [==============================] - 0s 441us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 112/150\n",
      "400/400 [==============================] - 0s 387us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 113/150\n",
      "400/400 [==============================] - 0s 437us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 114/150\n",
      "400/400 [==============================] - 0s 385us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 115/150\n",
      "400/400 [==============================] - 0s 388us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 116/150\n",
      "400/400 [==============================] - 0s 647us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 117/150\n",
      "400/400 [==============================] - 0s 608us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 118/150\n",
      "400/400 [==============================] - 0s 450us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 119/150\n",
      "400/400 [==============================] - 0s 375us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 120/150\n",
      "400/400 [==============================] - 0s 452us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 121/150\n",
      "400/400 [==============================] - 0s 510us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 122/150\n",
      "400/400 [==============================] - 0s 483us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 123/150\n",
      "400/400 [==============================] - 0s 390us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 124/150\n",
      "400/400 [==============================] - 0s 402us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 125/150\n",
      "400/400 [==============================] - 0s 372us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 126/150\n",
      "400/400 [==============================] - 0s 425us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 127/150\n",
      "400/400 [==============================] - 0s 392us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 128/150\n",
      "400/400 [==============================] - 0s 395us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 129/150\n",
      "400/400 [==============================] - 0s 357us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 130/150\n",
      "400/400 [==============================] - 0s 332us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 131/150\n",
      "400/400 [==============================] - 0s 370us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 132/150\n",
      "400/400 [==============================] - 0s 390us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 133/150\n",
      "400/400 [==============================] - 0s 390us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 134/150\n",
      "400/400 [==============================] - 0s 445us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 135/150\n",
      "400/400 [==============================] - 0s 377us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 136/150\n",
      "400/400 [==============================] - 0s 345us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 137/150\n",
      "400/400 [==============================] - 0s 372us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 138/150\n",
      "400/400 [==============================] - 0s 377us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 139/150\n",
      "400/400 [==============================] - 0s 363us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 140/150\n",
      "400/400 [==============================] - 0s 345us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 141/150\n",
      "400/400 [==============================] - 0s 360us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 142/150\n",
      "400/400 [==============================] - 0s 355us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 143/150\n",
      "400/400 [==============================] - 0s 357us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 144/150\n",
      "400/400 [==============================] - 0s 352us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 145/150\n",
      "400/400 [==============================] - 0s 362us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 146/150\n",
      "400/400 [==============================] - 0s 353us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 147/150\n",
      "400/400 [==============================] - 0s 385us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 148/150\n",
      "400/400 [==============================] - 0s 355us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 149/150\n",
      "400/400 [==============================] - 0s 362us/step - loss: 6.8951 - acc: 0.5675\n",
      "Epoch 150/150\n",
      "400/400 [==============================] - 0s 347us/step - loss: 6.8951 - acc: 0.5675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2664cc3c358>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs = 150, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 0s 2ms/step\n",
      "\n",
      "acc: 76.92%\n"
     ]
    }
   ],
   "source": [
    "mse, mae = model.evaluate(test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], mae*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказано: 1.0 , правильно 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Предсказано:\", pred[1][0], \", правильно\", y_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Многоклассовая класификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3)\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "y = np_utils.to_categorical(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = X[:110]\n",
    "y_train = y[:110]\n",
    "test = X[110:]\n",
    "y_test = y[110:]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr = 0.001)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 3)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2841 - acc: 0.9091\n",
      "Epoch 2/250\n",
      "110/110 [==============================] - 0s 309us/step - loss: 0.2841 - acc: 0.9091\n",
      "Epoch 3/250\n",
      "110/110 [==============================] - 0s 327us/step - loss: 0.2836 - acc: 0.9091\n",
      "Epoch 4/250\n",
      "110/110 [==============================] - 0s 318us/step - loss: 0.2835 - acc: 0.9091\n",
      "Epoch 5/250\n",
      "110/110 [==============================] - 0s 427us/step - loss: 0.2836 - acc: 0.9091\n",
      "Epoch 6/250\n",
      "110/110 [==============================] - 0s 427us/step - loss: 0.2834 - acc: 0.9091\n",
      "Epoch 7/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2832 - acc: 0.9091\n",
      "Epoch 8/250\n",
      "110/110 [==============================] - 0s 318us/step - loss: 0.2831 - acc: 0.9091\n",
      "Epoch 9/250\n",
      "110/110 [==============================] - 0s 327us/step - loss: 0.2832 - acc: 0.9091\n",
      "Epoch 10/250\n",
      "110/110 [==============================] - 0s 327us/step - loss: 0.2827 - acc: 0.9091\n",
      "Epoch 11/250\n",
      "110/110 [==============================] - 0s 436us/step - loss: 0.2825 - acc: 0.9091\n",
      "Epoch 12/250\n",
      "110/110 [==============================] - 0s 427us/step - loss: 0.2825 - acc: 0.9091\n",
      "Epoch 13/250\n",
      "110/110 [==============================] - 0s 364us/step - loss: 0.2821 - acc: 0.9091\n",
      "Epoch 14/250\n",
      "110/110 [==============================] - 0s 618us/step - loss: 0.2821 - acc: 0.9091\n",
      "Epoch 15/250\n",
      "110/110 [==============================] - 0s 382us/step - loss: 0.2824 - acc: 0.9091\n",
      "Epoch 16/250\n",
      "110/110 [==============================] - 0s 500us/step - loss: 0.2819 - acc: 0.9091\n",
      "Epoch 17/250\n",
      "110/110 [==============================] - 0s 327us/step - loss: 0.2819 - acc: 0.9091\n",
      "Epoch 18/250\n",
      "110/110 [==============================] - 0s 309us/step - loss: 0.2817 - acc: 0.9091\n",
      "Epoch 19/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2814 - acc: 0.9091\n",
      "Epoch 20/250\n",
      "110/110 [==============================] - 0s 473us/step - loss: 0.2815 - acc: 0.9091\n",
      "Epoch 21/250\n",
      "110/110 [==============================] - 0s 464us/step - loss: 0.2812 - acc: 0.9091\n",
      "Epoch 22/250\n",
      "110/110 [==============================] - 0s 500us/step - loss: 0.2809 - acc: 0.9091\n",
      "Epoch 23/250\n",
      "110/110 [==============================] - 0s 518us/step - loss: 0.2812 - acc: 0.9091\n",
      "Epoch 24/250\n",
      "110/110 [==============================] - 0s 445us/step - loss: 0.2808 - acc: 0.9091\n",
      "Epoch 25/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2806 - acc: 0.9091\n",
      "Epoch 26/250\n",
      "110/110 [==============================] - 0s 355us/step - loss: 0.2808 - acc: 0.9091\n",
      "Epoch 27/250\n",
      "110/110 [==============================] - 0s 400us/step - loss: 0.2806 - acc: 0.9091\n",
      "Epoch 28/250\n",
      "110/110 [==============================] - 0s 509us/step - loss: 0.2803 - acc: 0.9091\n",
      "Epoch 29/250\n",
      "110/110 [==============================] - 0s 318us/step - loss: 0.2803 - acc: 0.9091\n",
      "Epoch 30/250\n",
      "110/110 [==============================] - 0s 491us/step - loss: 0.2798 - acc: 0.9091\n",
      "Epoch 31/250\n",
      "110/110 [==============================] - 0s 400us/step - loss: 0.2794 - acc: 0.9091\n",
      "Epoch 32/250\n",
      "110/110 [==============================] - 0s 482us/step - loss: 0.2798 - acc: 0.9091\n",
      "Epoch 33/250\n",
      "110/110 [==============================] - 0s 373us/step - loss: 0.2795 - acc: 0.9091\n",
      "Epoch 34/250\n",
      "110/110 [==============================] - 0s 445us/step - loss: 0.2794 - acc: 0.9091\n",
      "Epoch 35/250\n",
      "110/110 [==============================] - 0s 364us/step - loss: 0.2791 - acc: 0.9091\n",
      "Epoch 36/250\n",
      "110/110 [==============================] - 0s 445us/step - loss: 0.2788 - acc: 0.9091\n",
      "Epoch 37/250\n",
      "110/110 [==============================] - 0s 773us/step - loss: 0.2790 - acc: 0.9091\n",
      "Epoch 38/250\n",
      "110/110 [==============================] - 0s 900us/step - loss: 0.2787 - acc: 0.9091\n",
      "Epoch 39/250\n",
      "110/110 [==============================] - 0s 491us/step - loss: 0.2787 - acc: 0.9091\n",
      "Epoch 40/250\n",
      "110/110 [==============================] - 0s 464us/step - loss: 0.2786 - acc: 0.9091\n",
      "Epoch 41/250\n",
      "110/110 [==============================] - 0s 364us/step - loss: 0.2784 - acc: 0.9091\n",
      "Epoch 42/250\n",
      "110/110 [==============================] - 0s 527us/step - loss: 0.2780 - acc: 0.9091\n",
      "Epoch 43/250\n",
      "110/110 [==============================] - 0s 491us/step - loss: 0.2781 - acc: 0.9091\n",
      "Epoch 44/250\n",
      "110/110 [==============================] - 0s 354us/step - loss: 0.2777 - acc: 0.9091\n",
      "Epoch 45/250\n",
      "110/110 [==============================] - 0s 545us/step - loss: 0.2777 - acc: 0.9091\n",
      "Epoch 46/250\n",
      "110/110 [==============================] - 0s 473us/step - loss: 0.2777 - acc: 0.9091\n",
      "Epoch 47/250\n",
      "110/110 [==============================] - 0s 418us/step - loss: 0.2774 - acc: 0.9091\n",
      "Epoch 48/250\n",
      "110/110 [==============================] - 0s 545us/step - loss: 0.2772 - acc: 0.9091\n",
      "Epoch 49/250\n",
      "110/110 [==============================] - 0s 491us/step - loss: 0.2770 - acc: 0.9091\n",
      "Epoch 50/250\n",
      "110/110 [==============================] - 0s 427us/step - loss: 0.2771 - acc: 0.9091\n",
      "Epoch 51/250\n",
      "110/110 [==============================] - 0s 756us/step - loss: 0.2770 - acc: 0.9091\n",
      "Epoch 52/250\n",
      "110/110 [==============================] - 0s 836us/step - loss: 0.2769 - acc: 0.9091\n",
      "Epoch 53/250\n",
      "110/110 [==============================] - 0s 491us/step - loss: 0.2781 - acc: 0.9091\n",
      "Epoch 54/250\n",
      "110/110 [==============================] - 0s 418us/step - loss: 0.2764 - acc: 0.9091\n",
      "Epoch 55/250\n",
      "110/110 [==============================] - 0s 355us/step - loss: 0.2767 - acc: 0.9091\n",
      "Epoch 56/250\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2762 - acc: 0.9091\n",
      "Epoch 57/250\n",
      "110/110 [==============================] - 0s 691us/step - loss: 0.2761 - acc: 0.9091\n",
      "Epoch 58/250\n",
      "110/110 [==============================] - 0s 905us/step - loss: 0.2758 - acc: 0.9091\n",
      "Epoch 59/250\n",
      "110/110 [==============================] - 0s 515us/step - loss: 0.2762 - acc: 0.9091\n",
      "Epoch 60/250\n",
      "110/110 [==============================] - 0s 473us/step - loss: 0.2758 - acc: 0.9091\n",
      "Epoch 61/250\n",
      "110/110 [==============================] - 0s 473us/step - loss: 0.2762 - acc: 0.9091\n",
      "Epoch 62/250\n",
      "110/110 [==============================] - 0s 527us/step - loss: 0.2762 - acc: 0.9091\n",
      "Epoch 63/250\n",
      "110/110 [==============================] - 0s 836us/step - loss: 0.2753 - acc: 0.9091\n",
      "Epoch 64/250\n",
      "110/110 [==============================] - 0s 427us/step - loss: 0.2757 - acc: 0.9091\n",
      "Epoch 65/250\n",
      "110/110 [==============================] - 0s 418us/step - loss: 0.2752 - acc: 0.9091\n",
      "Epoch 66/250\n",
      "110/110 [==============================] - 0s 500us/step - loss: 0.2751 - acc: 0.9091\n",
      "Epoch 67/250\n",
      "110/110 [==============================] - 0s 527us/step - loss: 0.2748 - acc: 0.9091\n",
      "Epoch 68/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2747 - acc: 0.9091\n",
      "Epoch 69/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2744 - acc: 0.9091\n",
      "Epoch 70/250\n",
      "110/110 [==============================] - 0s 336us/step - loss: 0.2747 - acc: 0.9091\n",
      "Epoch 71/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2744 - acc: 0.9091\n",
      "Epoch 72/250\n",
      "110/110 [==============================] - 0s 564us/step - loss: 0.2742 - acc: 0.9091\n",
      "Epoch 73/250\n",
      "110/110 [==============================] - 0s 464us/step - loss: 0.2742 - acc: 0.9091\n",
      "Epoch 74/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2739 - acc: 0.9091\n",
      "Epoch 75/250\n",
      "110/110 [==============================] - 0s 500us/step - loss: 0.2737 - acc: 0.9091\n",
      "Epoch 76/250\n",
      "110/110 [==============================] - 0s 400us/step - loss: 0.2737 - acc: 0.9091\n",
      "Epoch 77/250\n",
      "110/110 [==============================] - 0s 436us/step - loss: 0.2735 - acc: 0.9091\n",
      "Epoch 78/250\n",
      "110/110 [==============================] - 0s 436us/step - loss: 0.2736 - acc: 0.9091\n",
      "Epoch 79/250\n",
      "110/110 [==============================] - 0s 400us/step - loss: 0.2734 - acc: 0.9091\n",
      "Epoch 80/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2729 - acc: 0.9091\n",
      "Epoch 81/250\n",
      "110/110 [==============================] - 0s 555us/step - loss: 0.2732 - acc: 0.9091\n",
      "Epoch 82/250\n",
      "110/110 [==============================] - 0s 509us/step - loss: 0.2732 - acc: 0.9091\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 364us/step - loss: 0.2729 - acc: 0.9091\n",
      "Epoch 84/250\n",
      "110/110 [==============================] - 0s 927us/step - loss: 0.2724 - acc: 0.9091\n",
      "Epoch 85/250\n",
      "110/110 [==============================] - 0s 509us/step - loss: 0.2730 - acc: 0.9091\n",
      "Epoch 86/250\n",
      "110/110 [==============================] - 0s 473us/step - loss: 0.2724 - acc: 0.9091\n",
      "Epoch 87/250\n",
      "110/110 [==============================] - 0s 465us/step - loss: 0.2723 - acc: 0.9091\n",
      "Epoch 88/250\n",
      "110/110 [==============================] - 0s 455us/step - loss: 0.2722 - acc: 0.9091\n",
      "Epoch 89/250\n",
      "110/110 [==============================] - 0s 464us/step - loss: 0.2723 - acc: 0.9091\n",
      "Epoch 90/250\n",
      "110/110 [==============================] - 0s 529us/step - loss: 0.2719 - acc: 0.9091\n",
      "Epoch 91/250\n",
      "110/110 [==============================] - 0s 473us/step - loss: 0.2719 - acc: 0.9091\n",
      "Epoch 92/250\n",
      "110/110 [==============================] - 0s 436us/step - loss: 0.2717 - acc: 0.9091\n",
      "Epoch 93/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2716 - acc: 0.9091\n",
      "Epoch 94/250\n",
      "110/110 [==============================] - 0s 509us/step - loss: 0.2714 - acc: 0.9091\n",
      "Epoch 95/250\n",
      "110/110 [==============================] - 0s 527us/step - loss: 0.2715 - acc: 0.9091\n",
      "Epoch 96/250\n",
      "110/110 [==============================] - 0s 464us/step - loss: 0.2713 - acc: 0.9091\n",
      "Epoch 97/250\n",
      "110/110 [==============================] - 0s 455us/step - loss: 0.2710 - acc: 0.9091\n",
      "Epoch 98/250\n",
      "110/110 [==============================] - 0s 491us/step - loss: 0.2707 - acc: 0.9091\n",
      "Epoch 99/250\n",
      "110/110 [==============================] - 0s 509us/step - loss: 0.2708 - acc: 0.9091\n",
      "Epoch 100/250\n",
      "110/110 [==============================] - 0s 482us/step - loss: 0.2709 - acc: 0.9091\n",
      "Epoch 101/250\n",
      "110/110 [==============================] - 0s 455us/step - loss: 0.2707 - acc: 0.9091\n",
      "Epoch 102/250\n",
      "110/110 [==============================] - 0s 473us/step - loss: 0.2704 - acc: 0.9091\n",
      "Epoch 103/250\n",
      "110/110 [==============================] - 0s 727us/step - loss: 0.2701 - acc: 0.9091\n",
      "Epoch 104/250\n",
      "110/110 [==============================] - 0s 536us/step - loss: 0.2702 - acc: 0.9091\n",
      "Epoch 105/250\n",
      "110/110 [==============================] - 0s 464us/step - loss: 0.2701 - acc: 0.9091\n",
      "Epoch 106/250\n",
      "110/110 [==============================] - 0s 419us/step - loss: 0.2701 - acc: 0.9091\n",
      "Epoch 107/250\n",
      "110/110 [==============================] - 0s 784us/step - loss: 0.2698 - acc: 0.9091\n",
      "Epoch 108/250\n",
      "110/110 [==============================] - 0s 774us/step - loss: 0.2698 - acc: 0.9091\n",
      "Epoch 109/250\n",
      "110/110 [==============================] - 0s 709us/step - loss: 0.2694 - acc: 0.9091\n",
      "Epoch 110/250\n",
      "110/110 [==============================] - 0s 746us/step - loss: 0.2695 - acc: 0.9091\n",
      "Epoch 111/250\n",
      "110/110 [==============================] - 0s 805us/step - loss: 0.2695 - acc: 0.9091\n",
      "Epoch 112/250\n",
      "110/110 [==============================] - 0s 836us/step - loss: 0.2691 - acc: 0.9091\n",
      "Epoch 113/250\n",
      "110/110 [==============================] - 0s 691us/step - loss: 0.2691 - acc: 0.9091\n",
      "Epoch 114/250\n",
      "110/110 [==============================] - 0s 555us/step - loss: 0.2690 - acc: 0.9091\n",
      "Epoch 115/250\n",
      "110/110 [==============================] - 0s 1000us/step - loss: 0.2692 - acc: 0.90910s - loss: 0.2572 - acc: 0.911\n",
      "Epoch 116/250\n",
      "110/110 [==============================] - 0s 500us/step - loss: 0.2690 - acc: 0.9091\n",
      "Epoch 117/250\n",
      "110/110 [==============================] - 0s 627us/step - loss: 0.2687 - acc: 0.9091\n",
      "Epoch 118/250\n",
      "110/110 [==============================] - 0s 820us/step - loss: 0.2684 - acc: 0.9091\n",
      "Epoch 119/250\n",
      "110/110 [==============================] - 0s 715us/step - loss: 0.2683 - acc: 0.9091\n",
      "Epoch 120/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2683 - acc: 0.9091\n",
      "Epoch 121/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2680 - acc: 0.9091\n",
      "Epoch 122/250\n",
      "110/110 [==============================] - 0s 573us/step - loss: 0.2680 - acc: 0.9091\n",
      "Epoch 123/250\n",
      "110/110 [==============================] - 0s 756us/step - loss: 0.2678 - acc: 0.9091\n",
      "Epoch 124/250\n",
      "110/110 [==============================] - 0s 710us/step - loss: 0.2681 - acc: 0.9091\n",
      "Epoch 125/250\n",
      "110/110 [==============================] - 0s 636us/step - loss: 0.2678 - acc: 0.9091\n",
      "Epoch 126/250\n",
      "110/110 [==============================] - 0s 541us/step - loss: 0.2674 - acc: 0.9091\n",
      "Epoch 127/250\n",
      "110/110 [==============================] - 0s 396us/step - loss: 0.2677 - acc: 0.9091\n",
      "Epoch 128/250\n",
      "110/110 [==============================] - 0s 445us/step - loss: 0.2675 - acc: 0.9091\n",
      "Epoch 129/250\n",
      "110/110 [==============================] - 0s 491us/step - loss: 0.2672 - acc: 0.9091\n",
      "Epoch 130/250\n",
      "110/110 [==============================] - 0s 782us/step - loss: 0.2670 - acc: 0.9091\n",
      "Epoch 131/250\n",
      "110/110 [==============================] - 0s 827us/step - loss: 0.2669 - acc: 0.9091\n",
      "Epoch 132/250\n",
      "110/110 [==============================] - 0s 682us/step - loss: 0.2670 - acc: 0.9091\n",
      "Epoch 133/250\n",
      "110/110 [==============================] - 0s 723us/step - loss: 0.2675 - acc: 0.9091\n",
      "Epoch 134/250\n",
      "110/110 [==============================] - 0s 528us/step - loss: 0.2664 - acc: 0.9091\n",
      "Epoch 135/250\n",
      "110/110 [==============================] - 0s 791us/step - loss: 0.2662 - acc: 0.9091\n",
      "Epoch 136/250\n",
      "110/110 [==============================] - 0s 742us/step - loss: 0.2663 - acc: 0.9091\n",
      "Epoch 137/250\n",
      "110/110 [==============================] - 0s 550us/step - loss: 0.2661 - acc: 0.9182\n",
      "Epoch 138/250\n",
      "110/110 [==============================] - 0s 892us/step - loss: 0.2663 - acc: 0.9091\n",
      "Epoch 139/250\n",
      "110/110 [==============================] - 0s 591us/step - loss: 0.2662 - acc: 0.9091\n",
      "Epoch 140/250\n",
      "110/110 [==============================] - 0s 598us/step - loss: 0.2665 - acc: 0.9091\n",
      "Epoch 141/250\n",
      "110/110 [==============================] - 0s 473us/step - loss: 0.2655 - acc: 0.9091\n",
      "Epoch 142/250\n",
      "110/110 [==============================] - 0s 573us/step - loss: 0.2656 - acc: 0.9091\n",
      "Epoch 143/250\n",
      "110/110 [==============================] - 0s 560us/step - loss: 0.2655 - acc: 0.9091\n",
      "Epoch 144/250\n",
      "110/110 [==============================] - 0s 665us/step - loss: 0.2654 - acc: 0.9182\n",
      "Epoch 145/250\n",
      "110/110 [==============================] - 0s 500us/step - loss: 0.2653 - acc: 0.9091\n",
      "Epoch 146/250\n",
      "110/110 [==============================] - 0s 845us/step - loss: 0.2649 - acc: 0.9091\n",
      "Epoch 147/250\n",
      "110/110 [==============================] - 0s 609us/step - loss: 0.2651 - acc: 0.9091\n",
      "Epoch 148/250\n",
      "110/110 [==============================] - 0s 400us/step - loss: 0.2651 - acc: 0.9091\n",
      "Epoch 149/250\n",
      "110/110 [==============================] - 0s 436us/step - loss: 0.2647 - acc: 0.9091\n",
      "Epoch 150/250\n",
      "110/110 [==============================] - 0s 355us/step - loss: 0.2648 - acc: 0.9091\n",
      "Epoch 151/250\n",
      "110/110 [==============================] - 0s 355us/step - loss: 0.2648 - acc: 0.9091\n",
      "Epoch 152/250\n",
      "110/110 [==============================] - 0s 391us/step - loss: 0.2644 - acc: 0.9091\n",
      "Epoch 153/250\n",
      "110/110 [==============================] - 0s 300us/step - loss: 0.2645 - acc: 0.9091\n",
      "Epoch 154/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2646 - acc: 0.9091\n",
      "Epoch 155/250\n",
      "110/110 [==============================] - 0s 436us/step - loss: 0.2643 - acc: 0.9091\n",
      "Epoch 156/250\n",
      "110/110 [==============================] - 0s 436us/step - loss: 0.2638 - acc: 0.9091\n",
      "Epoch 157/250\n",
      "110/110 [==============================] - 0s 418us/step - loss: 0.2643 - acc: 0.9091\n",
      "Epoch 158/250\n",
      "110/110 [==============================] - 0s 427us/step - loss: 0.2638 - acc: 0.9182\n",
      "Epoch 159/250\n",
      "110/110 [==============================] - 0s 500us/step - loss: 0.2638 - acc: 0.9182\n",
      "Epoch 160/250\n",
      "110/110 [==============================] - 0s 382us/step - loss: 0.2642 - acc: 0.9091\n",
      "Epoch 161/250\n",
      "110/110 [==============================] - 0s 436us/step - loss: 0.2634 - acc: 0.9091\n",
      "Epoch 162/250\n",
      "110/110 [==============================] - 0s 545us/step - loss: 0.2633 - acc: 0.9091\n",
      "Epoch 163/250\n",
      "110/110 [==============================] - 0s 355us/step - loss: 0.2634 - acc: 0.9091\n",
      "Epoch 164/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 373us/step - loss: 0.2637 - acc: 0.9091\n",
      "Epoch 165/250\n",
      "110/110 [==============================] - 0s 555us/step - loss: 0.2637 - acc: 0.9182\n",
      "Epoch 166/250\n",
      "110/110 [==============================] - 0s 991us/step - loss: 0.2628 - acc: 0.9091\n",
      "Epoch 167/250\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.2476 - acc: 0.914 - 0s 708us/step - loss: 0.2631 - acc: 0.9091\n",
      "Epoch 168/250\n",
      "110/110 [==============================] - 0s 418us/step - loss: 0.2626 - acc: 0.9182\n",
      "Epoch 169/250\n",
      "110/110 [==============================] - 0s 418us/step - loss: 0.2626 - acc: 0.9182\n",
      "Epoch 170/250\n",
      "110/110 [==============================] - 0s 492us/step - loss: 0.2624 - acc: 0.9091\n",
      "Epoch 171/250\n",
      "110/110 [==============================] - 0s 529us/step - loss: 0.2627 - acc: 0.9091\n",
      "Epoch 172/250\n",
      "110/110 [==============================] - 0s 491us/step - loss: 0.2627 - acc: 0.9091\n",
      "Epoch 173/250\n",
      "110/110 [==============================] - 0s 418us/step - loss: 0.2622 - acc: 0.9091\n",
      "Epoch 174/250\n",
      "110/110 [==============================] - 0s 418us/step - loss: 0.2620 - acc: 0.9091\n",
      "Epoch 175/250\n",
      "110/110 [==============================] - 0s 354us/step - loss: 0.2618 - acc: 0.9091\n",
      "Epoch 176/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2622 - acc: 0.9182\n",
      "Epoch 177/250\n",
      "110/110 [==============================] - 0s 718us/step - loss: 0.2618 - acc: 0.9182\n",
      "Epoch 178/250\n",
      "110/110 [==============================] - 0s 427us/step - loss: 0.2619 - acc: 0.9182\n",
      "Epoch 179/250\n",
      "110/110 [==============================] - 0s 491us/step - loss: 0.2619 - acc: 0.9182\n",
      "Epoch 180/250\n",
      "110/110 [==============================] - 0s 737us/step - loss: 0.2618 - acc: 0.9091\n",
      "Epoch 181/250\n",
      "110/110 [==============================] - 0s 468us/step - loss: 0.2615 - acc: 0.9182\n",
      "Epoch 182/250\n",
      "110/110 [==============================] - 0s 465us/step - loss: 0.2611 - acc: 0.9091\n",
      "Epoch 183/250\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2614 - acc: 0.9091\n",
      "Epoch 184/250\n",
      "110/110 [==============================] - 0s 436us/step - loss: 0.2609 - acc: 0.9182\n",
      "Epoch 185/250\n",
      "110/110 [==============================] - 0s 391us/step - loss: 0.2609 - acc: 0.9182\n",
      "Epoch 186/250\n",
      "110/110 [==============================] - 0s 527us/step - loss: 0.2608 - acc: 0.9091\n",
      "Epoch 187/250\n",
      "110/110 [==============================] - 0s 500us/step - loss: 0.2607 - acc: 0.9182\n",
      "Epoch 188/250\n",
      "110/110 [==============================] - 0s 518us/step - loss: 0.2606 - acc: 0.9091\n",
      "Epoch 189/250\n",
      "110/110 [==============================] - 0s 464us/step - loss: 0.2606 - acc: 0.9091\n",
      "Epoch 190/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2602 - acc: 0.9182\n",
      "Epoch 191/250\n",
      "110/110 [==============================] - 0s 400us/step - loss: 0.2600 - acc: 0.9182\n",
      "Epoch 192/250\n",
      "110/110 [==============================] - 0s 418us/step - loss: 0.2603 - acc: 0.9182\n",
      "Epoch 193/250\n",
      "110/110 [==============================] - 0s 400us/step - loss: 0.2600 - acc: 0.9182\n",
      "Epoch 194/250\n",
      "110/110 [==============================] - 0s 445us/step - loss: 0.2602 - acc: 0.9091\n",
      "Epoch 195/250\n",
      "110/110 [==============================] - 0s 382us/step - loss: 0.2596 - acc: 0.9182\n",
      "Epoch 196/250\n",
      "110/110 [==============================] - 0s 364us/step - loss: 0.2596 - acc: 0.9182\n",
      "Epoch 197/250\n",
      "110/110 [==============================] - 0s 364us/step - loss: 0.2596 - acc: 0.9182\n",
      "Epoch 198/250\n",
      "110/110 [==============================] - 0s 382us/step - loss: 0.2598 - acc: 0.9091\n",
      "Epoch 199/250\n",
      "110/110 [==============================] - 0s 436us/step - loss: 0.2596 - acc: 0.9182\n",
      "Epoch 200/250\n",
      "110/110 [==============================] - 0s 427us/step - loss: 0.2593 - acc: 0.9182\n",
      "Epoch 201/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2591 - acc: 0.9182\n",
      "Epoch 202/250\n",
      "110/110 [==============================] - 0s 455us/step - loss: 0.2592 - acc: 0.9182\n",
      "Epoch 203/250\n",
      "110/110 [==============================] - 0s 509us/step - loss: 0.2590 - acc: 0.9182\n",
      "Epoch 204/250\n",
      "110/110 [==============================] - 0s 355us/step - loss: 0.2588 - acc: 0.9182\n",
      "Epoch 205/250\n",
      "110/110 [==============================] - 0s 318us/step - loss: 0.2588 - acc: 0.9182\n",
      "Epoch 206/250\n",
      "110/110 [==============================] - 0s 373us/step - loss: 0.2589 - acc: 0.9182\n",
      "Epoch 207/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2587 - acc: 0.9091\n",
      "Epoch 208/250\n",
      "110/110 [==============================] - 0s 373us/step - loss: 0.2581 - acc: 0.9182\n",
      "Epoch 209/250\n",
      "110/110 [==============================] - 0s 327us/step - loss: 0.2584 - acc: 0.9182\n",
      "Epoch 210/250\n",
      "110/110 [==============================] - 0s 382us/step - loss: 0.2581 - acc: 0.9182\n",
      "Epoch 211/250\n",
      "110/110 [==============================] - 0s 355us/step - loss: 0.2579 - acc: 0.9182\n",
      "Epoch 212/250\n",
      "110/110 [==============================] - 0s 364us/step - loss: 0.2581 - acc: 0.9091\n",
      "Epoch 213/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2582 - acc: 0.9182\n",
      "Epoch 214/250\n",
      "110/110 [==============================] - 0s 427us/step - loss: 0.2580 - acc: 0.9091\n",
      "Epoch 215/250\n",
      "110/110 [==============================] - 0s 355us/step - loss: 0.2580 - acc: 0.9182\n",
      "Epoch 216/250\n",
      "110/110 [==============================] - 0s 327us/step - loss: 0.2579 - acc: 0.9182\n",
      "Epoch 217/250\n",
      "110/110 [==============================] - 0s 355us/step - loss: 0.2574 - acc: 0.9182\n",
      "Epoch 218/250\n",
      "110/110 [==============================] - 0s 309us/step - loss: 0.2573 - acc: 0.9182\n",
      "Epoch 219/250\n",
      "110/110 [==============================] - 0s 382us/step - loss: 0.2575 - acc: 0.9182\n",
      "Epoch 220/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2572 - acc: 0.9182\n",
      "Epoch 221/250\n",
      "110/110 [==============================] - 0s 373us/step - loss: 0.2573 - acc: 0.9182\n",
      "Epoch 222/250\n",
      "110/110 [==============================] - 0s 291us/step - loss: 0.2572 - acc: 0.9182\n",
      "Epoch 223/250\n",
      "110/110 [==============================] - 0s 391us/step - loss: 0.2569 - acc: 0.9182\n",
      "Epoch 224/250\n",
      "110/110 [==============================] - 0s 309us/step - loss: 0.2567 - acc: 0.9182\n",
      "Epoch 225/250\n",
      "110/110 [==============================] - 0s 373us/step - loss: 0.2566 - acc: 0.9182\n",
      "Epoch 226/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2566 - acc: 0.9182\n",
      "Epoch 227/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2566 - acc: 0.9182\n",
      "Epoch 228/250\n",
      "110/110 [==============================] - 0s 318us/step - loss: 0.2562 - acc: 0.9182\n",
      "Epoch 229/250\n",
      "110/110 [==============================] - 0s 382us/step - loss: 0.2564 - acc: 0.9182\n",
      "Epoch 230/250\n",
      "110/110 [==============================] - 0s 327us/step - loss: 0.2562 - acc: 0.9182\n",
      "Epoch 231/250\n",
      "110/110 [==============================] - 0s 409us/step - loss: 0.2565 - acc: 0.9182\n",
      "Epoch 232/250\n",
      "110/110 [==============================] - 0s 345us/step - loss: 0.2560 - acc: 0.9182\n",
      "Epoch 233/250\n",
      "110/110 [==============================] - 0s 464us/step - loss: 0.2558 - acc: 0.9182\n",
      "Epoch 234/250\n",
      "110/110 [==============================] - 0s 545us/step - loss: 0.2560 - acc: 0.9182\n",
      "Epoch 235/250\n",
      "110/110 [==============================] - 0s 445us/step - loss: 0.2555 - acc: 0.9182\n",
      "Epoch 236/250\n",
      "110/110 [==============================] - 0s 536us/step - loss: 0.2558 - acc: 0.9182\n",
      "Epoch 237/250\n",
      "110/110 [==============================] - 0s 391us/step - loss: 0.2556 - acc: 0.9182\n",
      "Epoch 238/250\n",
      "110/110 [==============================] - 0s 500us/step - loss: 0.2555 - acc: 0.9182\n",
      "Epoch 239/250\n",
      "110/110 [==============================] - 0s 373us/step - loss: 0.2552 - acc: 0.9182\n",
      "Epoch 240/250\n",
      "110/110 [==============================] - 0s 536us/step - loss: 0.2550 - acc: 0.9182\n",
      "Epoch 241/250\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2551 - acc: 0.9182\n",
      "Epoch 242/250\n",
      "110/110 [==============================] - 0s 664us/step - loss: 0.2558 - acc: 0.9091\n",
      "Epoch 243/250\n",
      "110/110 [==============================] - 0s 391us/step - loss: 0.2549 - acc: 0.9182\n",
      "Epoch 244/250\n",
      "110/110 [==============================] - 0s 445us/step - loss: 0.2547 - acc: 0.9182\n",
      "Epoch 245/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 582us/step - loss: 0.2552 - acc: 0.9182\n",
      "Epoch 246/250\n",
      "110/110 [==============================] - 0s 473us/step - loss: 0.2547 - acc: 0.9182\n",
      "Epoch 247/250\n",
      "110/110 [==============================] - 0s 391us/step - loss: 0.2547 - acc: 0.9182\n",
      "Epoch 248/250\n",
      "110/110 [==============================] - 0s 400us/step - loss: 0.2545 - acc: 0.9182\n",
      "Epoch 249/250\n",
      "110/110 [==============================] - 0s 400us/step - loss: 0.2543 - acc: 0.9182\n",
      "Epoch 250/250\n",
      "110/110 [==============================] - 0s 536us/step - loss: 0.2540 - acc: 0.9182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2664fb566d8>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs = 250, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 240us/step\n",
      "\n",
      "acc: 67.33%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
