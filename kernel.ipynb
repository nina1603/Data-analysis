{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt  \n\nfrom timeit import default_timer as timer\nfrom sklearn import preprocessing\n\n#!pip install ultimate\n#from ultimate.mlp import MLP \n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import ModelCheckpoint\n\nimport gc, sys\ngc.enable()\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7de68f6d7025d1525879b0f0dd157a53dc9cf215"
      },
      "cell_type": "code",
      "source": "def state(message,start = True, time = 0):\n    if(start):\n        print(f'Working on {message} ... ')\n    else :\n        print(f'Working on {message} took ({round(time , 3)}) Sec \\n')",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "52f9f587f8598eb43ed853b1ec10edbe464caa8f"
      },
      "cell_type": "code",
      "source": "def feature_engineering(is_train = True):\n    if is_train: \n        df = pd.read_csv('../input/train_V2.csv')\n        # Only take the samples with matches that have more than 1 player; there are matches with no players or just one player\n        df = df[df['maxPlace'] > 1]\n    else:\n        df = pd.read_csv('../input/test_V2.csv')\n        \n    # Make a new feature indecating the total distance a player cut :\n    state('totalDistance')\n    s = timer()\n    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n    e = timer()\n    state('totalDistance', False, e - s)\n    state('rankPoints')\n    \n    s = timer()\n    df['rankPoints'] = np.where(df['rankPoints'] <= 0 ,0 , df['rankPoints'])\n    \n    e = timer()                                  \n    state('rankPoints', False, e-s)\n    \n    target = 'winPlacePerc'\n    \n    features = list(df.columns)\n    features.remove(\"Id\")\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    features.remove(\"matchDuration\")\n    features.remove(\"matchType\")\n    y = None\n\n    if is_train: \n        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype = np.float64)\n        features.remove(target)\n    \n    # Make new features indicating the mean of the features(grouped by match and group) :\n    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n    # Put the new features into a rank form ( max value will have the highest rank)\n    agg_rank = agg.groupby('matchId')[features].rank(pct = True).reset_index()\n    \n\n    if is_train:\n        df_out = agg.reset_index()[['matchId','groupId']]\n    else:\n        df_out = df[['matchId','groupId']]\n    \n    df_out = df_out.merge(agg.reset_index(), suffixes = [\"\", \"\"], how = 'left', on = ['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes = [\"_mean\", \"_mean_rank\"], how = 'left', on = ['matchId', 'groupId'])\n    \n    # Make new features indicating the max value of the features for each group ( grouped by match )\n    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n    # Put the new features into a rank form ( max value will have the highest rank)\n    agg_rank = agg.groupby('matchId')[features].rank(pct = True).reset_index()\n    \n    # Merge the new (agg and agg_rank) with df_out :\n    df_out = df_out.merge(agg.reset_index(), suffixes = [\"\", \"\"], how = 'left', on = ['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes = [\"_max\", \"_max_rank\"], how = 'left', on = ['matchId', 'groupId'])\n    \n    # Make new features indicating the minimum value of the features for each group(grouped by match)\n    print(\"get group min feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n    # Put the new features into a rank form ( max value will have the highest rank)\n    agg_rank = agg.groupby('matchId')[features].rank(pct = True).reset_index()\n    \n    # Merge the new (agg and agg_rank) with df_out :\n    df_out = df_out.merge(agg.reset_index(), suffixes = [\"\", \"\"], how = 'left', on = ['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes = [\"_min\", \"_min_rank\"], how = 'left', on = ['matchId', 'groupId'])\n    \n    # Make new features indicating the number of players in each group ( grouped by match )\n    print(\"get group size feature\")\n    agg = df.groupby(['matchId','groupId']).size().reset_index(name = 'group_size')\n     \n    # Merge the group_size feature with df_out :\n    df_out = df_out.merge(agg, how = 'left', on = ['matchId', 'groupId'])\n    \n    # Make new features indicating the mean value of each features for each match :\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    \n    # Merge the new agg with df_out :\n    df_out = df_out.merge(agg, suffixes = [\"\", \"_match_mean\"], how = 'left', on = ['matchId'])\n    \n    agg = df.groupby(['matchId']).size().reset_index(name = 'match_size')\n    \n    df_out = df_out.merge(agg, how = 'left', on = ['matchId'])\n    df_out.drop([\"matchId\", \"groupId\"], axis = 1, inplace = True)\n\n    X = np.array(df_out, dtype = np.float64)\n    \n    del df, df_out, agg, agg_rank\n    gc.collect()\n    return X, y",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "499f0abf163f856955669933edd273cec25fa73f"
      },
      "cell_type": "code",
      "source": "%%time\n# Process the training data :\nx_train, y = feature_engineering(True)\n# Scale the data to be in the range (-1 , 1)\nscaler = preprocessing.MinMaxScaler(feature_range = (-1, 1), copy = False).fit(x_train)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Working on totalDistance ... \nWorking on totalDistance took (0.138) Sec \n\nWorking on rankPoints ... \nWorking on rankPoints took (0.048) Sec \n\nget group min feature\nget group size feature\nCPU times: user 2min 53s, sys: 30.9 s, total: 3min 24s\nWall time: 3min 24s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "0a5d03e9176791688223046195c5715d334e3680"
      },
      "cell_type": "markdown",
      "source": "Scale and normalize"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "acd2834f161bb3f98e617185fa4731f4a057f179"
      },
      "cell_type": "code",
      "source": "print(\"x_train: \", x_train.shape, x_train.max(), x_train.min())\nscaler.transform(x_train)\nprint(\"x_train now: \", x_train.shape, x_train.max(), x_train.min())",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "x_train:  (2026744, 170) 41270.1 0.0\nx_train now:  (2026744, 170) 1.0000000000000002 -1.0000000000000002\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "439db0f0573ee4141c99ddcc3f4e3cf902b9a0ab"
      },
      "cell_type": "code",
      "source": "y[:5]",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "array([0.3333, 0.037 , 0.    , 0.3704, 1.    ])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb1462f586c94ac31d562488574035eb54db87a0"
      },
      "cell_type": "code",
      "source": "y *= 2\ny -= 1\nprint(\"y\", y.shape, y.max(), y.min())",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "y (2026744,) 1.0 -1.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8519f6d0ca20826ce485cff25371fad296f53d4c"
      },
      "cell_type": "code",
      "source": "%%time\nmodel = Sequential()\nmodel.add(Dense(x_train.shape[1],  input_dim = x_train.shape[1], activation = 'relu'))\nmodel.add(Dense(136, activation = 'relu'))\nmodel.add(Dense(136, activation = 'relu'))\nmodel.add(Dense(136, activation = 'relu'))\nmodel.add(Dense(136, activation = 'relu'))\n\n# output Layer\nmodel.add(Dense(1, activation = 'linear'))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 76 ms, sys: 4 ms, total: 80 ms\nWall time: 79.8 ms\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb9fa9c5a556d3420fbf262600fa4aa08c2cc72a"
      },
      "cell_type": "code",
      "source": "# Compile the network :\nfrom keras.optimizers import SGD, Adam\nadam = Adam(lr=0.00001)\nmodel.compile(loss = 'mean_absolute_error', optimizer = 'adam', metrics=['mean_absolute_error'])\nmodel.summary()",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 170)               29070     \n_________________________________________________________________\ndense_2 (Dense)              (None, 136)               23256     \n_________________________________________________________________\ndense_3 (Dense)              (None, 136)               18632     \n_________________________________________________________________\ndense_4 (Dense)              (None, 136)               18632     \n_________________________________________________________________\ndense_5 (Dense)              (None, 136)               18632     \n_________________________________________________________________\ndense_6 (Dense)              (None, 1)                 137       \n=================================================================\nTotal params: 108,359\nTrainable params: 108,359\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9103ed2bddc91ec3ec2f35a473281899cbbd4c20"
      },
      "cell_type": "code",
      "source": "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \ncheckpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\ncallbacks_list = [checkpoint]\n",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4fedbc62e68404beaac48d5f9be666b6536046f"
      },
      "cell_type": "code",
      "source": "%%time\nmodel.fit(x = x_train, y = y, batch_size=1000, epochs=30, verbose=1, callbacks=callbacks_list,\n            validation_split=0.15, validation_data=None, shuffle=True,\n            class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\ndel x_train, y\ngc.collect()",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 1722732 samples, validate on 304012 samples\nEpoch 1/30\n1722732/1722732 [==============================] - 40s 23us/step - loss: 0.0769 - mean_absolute_error: 0.0769 - val_loss: 0.0689 - val_mean_absolute_error: 0.0689\n\nEpoch 00001: val_loss improved from inf to 0.06892, saving model to Weights-001--0.06892.hdf5\nEpoch 2/30\n1722732/1722732 [==============================] - 39s 22us/step - loss: 0.0658 - mean_absolute_error: 0.0658 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n\nEpoch 00002: val_loss did not improve from 0.06892\nEpoch 3/30\n1722732/1722732 [==============================] - 38s 22us/step - loss: 0.0643 - mean_absolute_error: 0.0643 - val_loss: 0.0655 - val_mean_absolute_error: 0.0655\n\nEpoch 00003: val_loss improved from 0.06892 to 0.06551, saving model to Weights-003--0.06551.hdf5\nEpoch 4/30\n1722732/1722732 [==============================] - 38s 22us/step - loss: 0.0631 - mean_absolute_error: 0.0631 - val_loss: 0.0621 - val_mean_absolute_error: 0.0621\n\nEpoch 00004: val_loss improved from 0.06551 to 0.06210, saving model to Weights-004--0.06210.hdf5\nEpoch 5/30\n1722732/1722732 [==============================] - 37s 21us/step - loss: 0.0624 - mean_absolute_error: 0.0624 - val_loss: 0.0617 - val_mean_absolute_error: 0.0617\n\nEpoch 00005: val_loss improved from 0.06210 to 0.06172, saving model to Weights-005--0.06172.hdf5\nEpoch 6/30\n1722732/1722732 [==============================] - 37s 22us/step - loss: 0.0620 - mean_absolute_error: 0.0620 - val_loss: 0.0609 - val_mean_absolute_error: 0.0609\n\nEpoch 00006: val_loss improved from 0.06172 to 0.06088, saving model to Weights-006--0.06088.hdf5\nEpoch 7/30\n1722732/1722732 [==============================] - 37s 22us/step - loss: 0.0617 - mean_absolute_error: 0.0617 - val_loss: 0.0616 - val_mean_absolute_error: 0.0616\n\nEpoch 00007: val_loss did not improve from 0.06088\nEpoch 8/30\n1722732/1722732 [==============================] - 37s 22us/step - loss: 0.0613 - mean_absolute_error: 0.0613 - val_loss: 0.0613 - val_mean_absolute_error: 0.0613\n\nEpoch 00008: val_loss did not improve from 0.06088\nEpoch 9/30\n1722732/1722732 [==============================] - 37s 22us/step - loss: 0.0613 - mean_absolute_error: 0.0613 - val_loss: 0.0612 - val_mean_absolute_error: 0.0612\n\nEpoch 00009: val_loss did not improve from 0.06088\nEpoch 10/30\n1722732/1722732 [==============================] - 39s 23us/step - loss: 0.0608 - mean_absolute_error: 0.0608 - val_loss: 0.0596 - val_mean_absolute_error: 0.0596\n\nEpoch 00010: val_loss improved from 0.06088 to 0.05962, saving model to Weights-010--0.05962.hdf5\nEpoch 11/30\n1722732/1722732 [==============================] - 38s 22us/step - loss: 0.0607 - mean_absolute_error: 0.0607 - val_loss: 0.0602 - val_mean_absolute_error: 0.0602\n\nEpoch 00011: val_loss did not improve from 0.05962\nEpoch 12/30\n1722732/1722732 [==============================] - 38s 22us/step - loss: 0.0604 - mean_absolute_error: 0.0604 - val_loss: 0.0611 - val_mean_absolute_error: 0.0611\n\nEpoch 00012: val_loss did not improve from 0.05962\nEpoch 13/30\n1722732/1722732 [==============================] - 37s 22us/step - loss: 0.0603 - mean_absolute_error: 0.0603 - val_loss: 0.0595 - val_mean_absolute_error: 0.0595\n\nEpoch 00013: val_loss improved from 0.05962 to 0.05951, saving model to Weights-013--0.05951.hdf5\nEpoch 14/30\n1722732/1722732 [==============================] - 37s 22us/step - loss: 0.0602 - mean_absolute_error: 0.0602 - val_loss: 0.0594 - val_mean_absolute_error: 0.0594\n\nEpoch 00014: val_loss improved from 0.05951 to 0.05937, saving model to Weights-014--0.05937.hdf5\nEpoch 15/30\n1722732/1722732 [==============================] - 38s 22us/step - loss: 0.0601 - mean_absolute_error: 0.0601 - val_loss: 0.0594 - val_mean_absolute_error: 0.0594\n\nEpoch 00015: val_loss did not improve from 0.05937\nEpoch 16/30\n1722732/1722732 [==============================] - 37s 22us/step - loss: 0.0601 - mean_absolute_error: 0.0601 - val_loss: 0.0591 - val_mean_absolute_error: 0.0591\n\nEpoch 00016: val_loss improved from 0.05937 to 0.05908, saving model to Weights-016--0.05908.hdf5\nEpoch 17/30\n1722732/1722732 [==============================] - 37s 21us/step - loss: 0.0596 - mean_absolute_error: 0.0596 - val_loss: 0.0593 - val_mean_absolute_error: 0.0593\n\nEpoch 00017: val_loss did not improve from 0.05908\nEpoch 18/30\n1722732/1722732 [==============================] - 38s 22us/step - loss: 0.0596 - mean_absolute_error: 0.0596 - val_loss: 0.0603 - val_mean_absolute_error: 0.0603\n\nEpoch 00018: val_loss did not improve from 0.05908\nEpoch 19/30\n1722732/1722732 [==============================] - 37s 21us/step - loss: 0.0596 - mean_absolute_error: 0.0596 - val_loss: 0.0588 - val_mean_absolute_error: 0.0588\n\nEpoch 00019: val_loss improved from 0.05908 to 0.05884, saving model to Weights-019--0.05884.hdf5\nEpoch 20/30\n1722732/1722732 [==============================] - 37s 21us/step - loss: 0.0594 - mean_absolute_error: 0.0594 - val_loss: 0.0587 - val_mean_absolute_error: 0.0587\n\nEpoch 00020: val_loss improved from 0.05884 to 0.05873, saving model to Weights-020--0.05873.hdf5\nEpoch 21/30\n1722732/1722732 [==============================] - 37s 21us/step - loss: 0.0595 - mean_absolute_error: 0.0595 - val_loss: 0.0634 - val_mean_absolute_error: 0.0634\n\nEpoch 00021: val_loss did not improve from 0.05873\nEpoch 22/30\n1722732/1722732 [==============================] - 38s 22us/step - loss: 0.0592 - mean_absolute_error: 0.0592 - val_loss: 0.0588 - val_mean_absolute_error: 0.0588\n\nEpoch 00022: val_loss did not improve from 0.05873\nEpoch 23/30\n1722732/1722732 [==============================] - 37s 21us/step - loss: 0.0592 - mean_absolute_error: 0.0592 - val_loss: 0.0586 - val_mean_absolute_error: 0.0586\n\nEpoch 00023: val_loss improved from 0.05873 to 0.05863, saving model to Weights-023--0.05863.hdf5\nEpoch 24/30\n1722732/1722732 [==============================] - 37s 21us/step - loss: 0.0590 - mean_absolute_error: 0.0590 - val_loss: 0.0597 - val_mean_absolute_error: 0.0597\n\nEpoch 00024: val_loss did not improve from 0.05863\nEpoch 25/30\n1722732/1722732 [==============================] - 37s 22us/step - loss: 0.0591 - mean_absolute_error: 0.0591 - val_loss: 0.0586 - val_mean_absolute_error: 0.0586\n\nEpoch 00025: val_loss did not improve from 0.05863\nEpoch 26/30\n1722732/1722732 [==============================] - 38s 22us/step - loss: 0.0590 - mean_absolute_error: 0.0590 - val_loss: 0.0589 - val_mean_absolute_error: 0.0589\n\nEpoch 00026: val_loss did not improve from 0.05863\nEpoch 27/30\n1722732/1722732 [==============================] - 38s 22us/step - loss: 0.0588 - mean_absolute_error: 0.0588 - val_loss: 0.0606 - val_mean_absolute_error: 0.0606\n\nEpoch 00027: val_loss did not improve from 0.05863\nEpoch 28/30\n1722732/1722732 [==============================] - 37s 21us/step - loss: 0.0589 - mean_absolute_error: 0.0589 - val_loss: 0.0579 - val_mean_absolute_error: 0.0579\n\nEpoch 00028: val_loss improved from 0.05863 to 0.05789, saving model to Weights-028--0.05789.hdf5\nEpoch 29/30\n1722732/1722732 [==============================] - 37s 22us/step - loss: 0.0587 - mean_absolute_error: 0.0587 - val_loss: 0.0613 - val_mean_absolute_error: 0.0613\n\nEpoch 00029: val_loss did not improve from 0.05789\nEpoch 30/30\n1722732/1722732 [==============================] - 37s 21us/step - loss: 0.0586 - mean_absolute_error: 0.0586 - val_loss: 0.0588 - val_mean_absolute_error: 0.0588\n\nEpoch 00030: val_loss did not improve from 0.05789\nCPU times: user 33min 3s, sys: 3min 27s, total: 36min 31s\nWall time: 18min 46s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "08e431058dc9147ff98cc35f0e18cc23703d6f3a"
      },
      "cell_type": "markdown",
      "source": "Downloading test set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d7026cdb61c4a81b71a59d1b88f6163d3b0b3298"
      },
      "cell_type": "code",
      "source": "x_test, _ = feature_engineering(False)\nscaler.transform(x_test)\nprint(\"x_test\", x_test.shape, x_test.max(), x_test.min())\nnp.clip(x_test, out=x_test, a_min=-1, a_max=1)\nprint(\"x_test\", x_test.shape, x_test.max(), x_test.min())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dad5bf612bcc20c9c4ef777d6d2f88f75bb02e72"
      },
      "cell_type": "markdown",
      "source": "Predict the target"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8aea5fa636578d35809506932df8bd54db32ecfe"
      },
      "cell_type": "code",
      "source": "%%time\npred = model.predict(x_test)\ndel x_test\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c4740e96b180ff7bff1f7fc40d7df8982a787e1a"
      },
      "cell_type": "code",
      "source": "pred = pred.reshape(-1)\npred = (pred + 1) / 2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0abb2dd724117bc247c097262f09d2bf5dc99e9a"
      },
      "cell_type": "code",
      "source": "df_test = pd.read_csv('../input/test_V2.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "36a1e68bf38ae46ec885d0816ab204f792812fcb"
      },
      "cell_type": "code",
      "source": "%%time\nprint(\"fix winPlacePerc\")\nfor i in range(len(df_test)):\n    winPlacePerc = pred[i]\n    maxPlace = int(df_test.iloc[i]['maxPlace'])\n    if maxPlace == 0:\n        winPlacePerc = 0.0\n    elif maxPlace == 1:\n        winPlacePerc = 1.0\n    else:\n        gap = 1.0 / (maxPlace - 1)\n        winPlacePerc = round(winPlacePerc / gap) * gap\n    \n    if winPlacePerc < 0: winPlacePerc = 0.0\n    if winPlacePerc > 1: winPlacePerc = 1.0    \n    pred[i] = winPlacePerc",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9e01f5e1bbbd24b26bb3443090c374d02944f08"
      },
      "cell_type": "code",
      "source": "df_test['winPlacePerc'] = pred",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3907ebab34e830126b6a6fb6e850f31a2c6caaeb"
      },
      "cell_type": "code",
      "source": "submission = df_test[['Id', 'winPlacePerc']]\nsubmission.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}